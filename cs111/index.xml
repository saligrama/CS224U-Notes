<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CS 111, Spring 2021 on Aditya's notes</title><link>https://saligrama.io/notes/cs111/</link><description>Recent content in CS 111, Spring 2021 on Aditya's notes</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://saligrama.io/notes/cs111/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://saligrama.io/notes/cs111/2021-03-31-threads-and-dispatching/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-03-31-threads-and-dispatching/</guid><description>Threads # Definition: a thread is a sequential execution stream (i.e., executes instructions sequentially, one after another)
Virtualization # Concept: one thing can behave like another - indistinguishably so
Why? Because modern computer hardware deals with threads in a complex, parallel (rather than serial) way, but we can treat threads as single units without having to worry about complex hardware interactions
Execution state # Definition: Everything that can affect a thread, or be affected by it</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-04-02-concurrency/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-04-02-concurrency/</guid><description>Concurrency # Independent threads # Definition: a thread that can&amp;rsquo;t effect or be affected by any other thread (execution state isn&amp;rsquo;t shared with other threads)
Properties:
Deterministic: input state exactly determines results Reproducible Scheduling order irrelevant Example: arithmetic operations
In practice: this almost never happens; thread states are almost always shared within the OS
Cooperating threads # Definition: Cooperating threads have a shared state
Properties:
Nondeterministic Not necessarily reproducible Example: suppose these are running on different threads</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-04-05-synchronization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-04-05-synchronization/</guid><description>Synchronization # Definition: Using atomic operations to ensure correct operation of cooperating threads (includes both safety and liveness properties)
Critical section: Piece of code where only one thread can execute at once
Mutual Exclusion (mutex): Mechanisms for implementing critical sections
Computerized milk purchase # if (milk == 0) { if (note == 0) { note = 1 buy_milk(); note = 0; } } This doesn&amp;rsquo;t work, because thread 1 can see a zero value for note while thread 0 is setting note to 1.</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-04-07-shared-memory-and-condition-variables-and-locks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-04-07-shared-memory-and-condition-variables-and-locks/</guid><description>Shared memory # Which variables are shared? # Programmer decides All memory potentially shareable (in process) Stack locals: private Globals: shared Pointers stored in globals: shared Pointers passed as arguments when instantiating threads: shared void my_func(int x) { int y; // private Pool p; // private } Pool p2; // public Thread safety # Refers to a class designed for shared use std::vector is not thread-safe For thread-unsafe classes: must manually lock externally Condition variables # std::condition_variable</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-04-09-lock-implementation-and-deadlocking/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-04-09-lock-implementation-and-deadlocking/</guid><description>Implementing locks # For multiple cores:
Atomic operations: read-modify-write Swap: Reads word Writes new value Returns old value Version 1: Spin Lock # class Lock { Lock() {} std::atomic&amp;lt;int&amp;gt; locked(0); } void Lock::lock() { while (locked.swap(1)) { // do nothing // continue looping until we get a 0 back (old value) } } void Lock::unlock() { locked = 0; } Version 2: less busy waiting # class Lock { Lock() {} std::atomic&amp;lt;int&amp;gt; locked(0); ThreadQueue q; } void Lock::lock() { if (locked.</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-04-12-scheduling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-04-12-scheduling/</guid><description>Single-core scheduling # Computational resources # Preemptible: Can give to a thread and can take it away Network interfaces Scheduling: how long thread keeps resources, who&amp;rsquo;s next Non-preemptible: Can&amp;rsquo;t take away without permission File space Allocation: who gets what Deciding which resources are preemptible or not is associated with the cost to preempt.
Which thread should run on which core for how long?
Goals # Minimize response time (to useful result - down to human response time of 50-100ms) Use resources efficiently Keep resources busy if there is work to do for them Minimize context switches First-come-first-serve (FCFS/FIFO) # Keep a ready queue of runnable threads When a thread becomes runnable, add it to the back When a core runs out of work to do (locks or exits), run first thread on queue Disadvantage: One thread can monopolize core</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-04-14-multiprocessing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-04-14-multiprocessing/</guid><description>Multiprocessor scheduling # Simple approach # Shared ready queue, lock One dispatcher per core Timer interrupts per core Core takes highest-priority thread and runs it When a thread becomes runnable:
If the new thread is higher priority, preempt existing thread Contention for lock and queues # Have a separate ready queue per core Balance load across cores (work stealing) Work conservation # If there is a ready thread currently queued, and there&amp;rsquo;s an idle core, thread will run on that core Core affinity # Expensive to move a thread to a new core Try to keep the thread on the same core Gang scheduling # Run threads of a process together (on different cores) Otherwise, what happens is: One thread locks Deschedule Other threads may block on lock Keep thread loaded even if blocked?</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-04-16-linking/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-04-16-linking/</guid><description>Linking # Memory # Process memory layout:
Process creation # Linkers # Unix: ld Windows: LINK.exe What does it do?
Combine object files (compiled from source) Computes memory layout Fix memory addresses Produces executable Problems it has to deal with:
Assembler doesn&amp;rsquo;t know where code or data will go in memory Makes a guess: Assume sections will be located at 0, write everything as such Assembler doesn&amp;rsquo;t know addresses of external objects Makes a guess: Assume 0 and leave a note for the linker Object file # Contains:</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-04-19-storage-management/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-04-19-storage-management/</guid><description>Dynamic storage management # Problem: unpredictability
Operations: # alloc(nbytes) -&amp;gt; ptr free(ptr) Stack allocation # Freeing is predictable: just LIFO order! Heap Allocation # Freeing is unpredictable Memory has allocated areas and free areas (&amp;ldquo;holes&amp;rdquo;) Fragmentation: Small holes, can&amp;rsquo;t effectively use for allocation
Goal: Minimize fragmentation
Free lists # Data structure that keeps track of holes
Best fit # Linked list of free blocks On allocation, scan entire list and pick the smallest block that can fit requested size On free, try to merge a block with its neighbors First fit: # Stop at first block that is large enough</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-04-21-virtual-memory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-04-21-virtual-memory/</guid><description>Virtual memory # How to share one set of memory between multiple processes?
Goals:
Multitasking: memory shared between processes running at the same time Transparency: user processes should not have awareness of shared memory Process should see only its own private pool of memory Isolation: one process can&amp;rsquo;t corrupt another Efficiency: don&amp;rsquo;t want to add extra runtime to OS code or complexity to use code Load-time relocation # When loading process,</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-04-23-dynamic-address-translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-04-23-dynamic-address-translation/</guid><description>Dynamic Address Translation # Goal: Make a process think it has its own memory space independent from all other processes
Process&amp;rsquo;s memory would start at 0 Hardware has
CPU core Memory management unit Converts virtual addresses (process memory space) to physical addresses (actual hardware memory address) Memory Base and Bound # Virtual address space goes from 0 to Bound Physical address for same process goes from Base to Base+Bound Properties:</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-04-26-segmentation-and-paging/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-04-26-segmentation-and-paging/</guid><description>Virtual memory schemes # Segmentation # Process has multiple segments of memory (code, data, stack)
MMU has a segment map with one entry per segment, with three fields:
Base Bound Writeable bit (is process allowed to modify the segment) Segment number can be from:
Top bits of virtual address Implicit from instruction Instructions vs data x86 prefixes Advantages:
Manage segments separately Move/swap to disk Share code segments between processes Have same base/bound numbers Disadvantages:</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-04-30-demand-paging/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-04-30-demand-paging/</guid><description>Demand paging # Program can run without loading everything into memory Keep active info in memory Inactive info on disk in paging file/backing store/swap space Locality: Most of the time, a process uses only a small fraction of its code and data
Disk: 100x cheaper than DRAM DRAM: 100,000x faster than disk Each page in VAS either
in memory (physical page frame) on disk in backing store Page fault procedure # Reference to page not in memory Present bit 0 Trap to OS Find tree page Read data from backing store Set present bit to 1 Resume execution Technicalities:</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-05-05-disks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-05-05-disks/</guid><description>Disks # 6-12 platters, each with 200k inch tracks, 1000 sectors per track, 4096 bytes per sector Total capacity ~100GB to 18TB I/O operation # Seek: position heads over track we want to read or write (2-10ms) Rotational latency: 4ms at 7500RPM Transfer: 100-150 MB/sec API: # void read(start_sector, sector_count, phys_mem_addr); void write(start_sector, sector_count, phys_mem_addr); Disk structure hidden because
Inner tracks have fewer sectors Disk can remap bad sectors Device registers # One block per device Words in physical memory Parameters Status bits (&amp;ldquo;completed&amp;rdquo;, &amp;ldquo;error&amp;rdquo;) Control bits set by CPU (&amp;ldquo;start operation&amp;rdquo;) Don&amp;rsquo;t behave like memory Some fields might always read as 0 Can change without being written to Operation # Write register to start Ready bit reads as 0 When operation does, ready bit reads as 1 Interrupts # &amp;ldquo;Interrupt enabled&amp;rdquo; (IE) bit in register After starting operation, OS will set this bit OS does something else When device becomes ready, checks IE bit If IE bit on, device interrupts when ready Save IP and PS Branch into OS, load new PS (stored in interrupt vector) Disable IE in handler Multi-core machines: spread interrupts to many cores</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-05-07-file-systems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-05-07-file-systems/</guid><description>File systems # Issues:
Disk space management File naming/lookup Reliability, file recovery Protection: isolating and sharing user data File # Definition: Named collection of bytes stored durably
Access patterns:
Sequential Random access: access by position Notes:
Most files are small: need to keep file metadata very small Large files occupy most of the disk Most IO for large files Files can grow Inode # Definition: OS info about a file</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-05-10-realworld-filesystem-structures/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-05-10-realworld-filesystem-structures/</guid><description>DOS/Windows FAT # Linked list: links in File Allocation Table One entry per block Next block in file &amp;ldquo;Last block&amp;rdquo; &amp;ldquo;Free block&amp;rdquo; Inode: first block in file Free list: like a bit map Originally: 16-bit entries, 512 byte blocks =&amp;gt; 32 Mb disks Advantages:
Random access is fairly fast Sequential access is easy FAT itself is free list! No pointers in data block Contiguous allocation is possible Disadvantages:
Fragmentation issues (but better than linked files) FAT32 # 28-bit sector numbers Clusters: groups of sectors, 2-32kb 4kb clusters: 1TB disks Multi-level indexes (4.</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-05-12-directories/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-05-12-directories/</guid><description>Inode allocation # Where on disk for inodes? Contiguous array at outer edge: lots of seeks Many arrays, spaced over disk FS tries to allocate data for an inode near the inode itself Index in array: i-number, unique identifier for a file Directories # Map from name to i-number Previously: one directory per disk, then per user Today: hierarchical directories Stored like regular files inode has special bit indicating it&amp;rsquo;s a directory Root directory has i-number 2 Procedure for looking up file # File: /a/b/c</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-05-14-crash-recovery/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-05-14-crash-recovery/</guid><description>Crash recovery # Crashes can happen anywhere Lost data Inconsistency Modification affects several blocks Add block to file: modify 2 blocks (bitmap, inode) &amp;ldquo;Atomic ops&amp;rdquo;: all or nothing for multi-block ops? fsck # Fix on reboot Checks to see if system shutdown cleanly Set flag on disk during normal shutdown If hard shutdown, flag won&amp;rsquo;t be set - then run fsck Reboot: clear flag If not, scan disk, find and fix inconsistencies Goals:</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-05-19-protection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-05-19-protection/</guid><description>Protection # Prevent accidental/intentional misuse Authentication: identify principal Authorization: who may do what Entacement Authentication # Passwords: secret info
Need to be long and secure Need lots of them! Phishing/social engineering works Must protect database: never store pwd in clear One-way transforms: given ciphertext, can&amp;rsquo;t compute clear text; different cleartext yields different ciphertext Key/badge
No need for secrecy If stolen, will know Requires physical presence to steal 2-factor authentication</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-05-24-flash-memory/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-05-24-flash-memory/</guid><description>Flash memory # Flash vs disk:
No moving parts More shock resistant 100x lower latency 5-10x higher cost per bit Flash vs DRAM:
Nonvolatile 5-10x lower cost per bit 1000x higher latency Hardware:
Individual chips can be up to 512GB Erase units: 256kb Pages: 512 or 4096 bytes Reads: pages Writes: Erase: sets all bits in an erase unit to 1 Writes: pages: logical AND with data written and data existing (0s never change back to 1) Wear-out: limit on how many erases can be invoked without degrading reliability (1k-100k) Performance:</description></item><item><title/><link>https://saligrama.io/notes/cs111/2021-05-28-virtual-machines/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs111/2021-05-28-virtual-machines/</guid><description>Virtual machines # &amp;ldquo;process&amp;rdquo; running in its own computer Can have many VMs on a single machine hypervisor: implements VM abstraction guest OS: runs in VM Hypervisors # Simulator, use file to hold virtual disk and software emulation of CPU/memory oprations Examples: Bochs, Emu 100x slower for computation 2x slower for I/O Use machine to simulate itself? Guest OS in user mode Most instructions execute natively Trap and simulate &amp;ldquo;unusual&amp;rdquo; instructions Simulating an OS # Privileged instructions (i.</description></item></channel></rss>