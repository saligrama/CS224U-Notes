<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CS 143, Spring 2022 on Aditya's notes</title><link>https://saligrama.io/notes/cs143/</link><description>Recent content in CS 143, Spring 2022 on Aditya's notes</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://saligrama.io/notes/cs143/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://saligrama.io/notes/cs143/2022-03-29-intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs143/2022-03-29-intro/</guid><description>Compilers # Course structure # Course has theoretical and practical aspects Need both in programming languages! Written assignments and exams cover theory Programming assignments cover the practical/systems part Course goal # Open lid of compilers and see inside Understand what they do, how they work, how to build them Correctness over performance Will not cover lots of optimizations - will need CS243 for it Course project # Write own compiler in four parts: PA1: lexer PA2: parser PA3: type checker PA4: code generation How are languages implemented?</description></item><item><title/><link>https://saligrama.io/notes/cs143/2022-03-31-language-design-and-cool/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs143/2022-03-31-language-design-and-cool/</guid><description>Language design # Languages are adopted to fill a void Enable a previously difficult/impossible application Can be orthogonal to language quality Programmer training is the dominant cost Languages with many users are rarely replaced Popular languages become ossified But easy to start in a new niche Why so many languages? # Application domains have distinctive and conflicting needs Rust: systems programming w/focus on security R: statistics w/focus on streams Python: scripting Julia: linear algebra Javascript: able to run in browser No universally accepted metrics for design Abstraction # Detatched from concrete details Information hiding: expose only the essential Modes of abstraction Via languages/compilers: higher level code, few machine dependencies Via functions/subroutines: abstract interface to behavior Via modules: export interfaces, hide implementation Via classes or abstract data types: bundle data with operations Types # Originally, few types FORTRAN: scalars, arrays LISP: no static type distinctions Realization: types help Allows expressing abstraction Lets compiler report many frequent errors Allows guaranteeing certain types of &amp;ldquo;safety&amp;rdquo; Reuse # Exploit common patterns in software systems Goal: mass-produced software components Two popular approaches Type parametrization: std::vector&amp;lt;int&amp;gt;, std::vector&amp;lt;double&amp;gt; Classes and inheritance: C++ derived classes C++ and Java have both Inheritance allows Specialization of existing abstractions Extension, modification, hidden behavior Trends # Language design Many new special-purpose languages Popular languages stick around (perhaps forever) Fortran and Cobol Compilers Ever more needed and more complex Driven by increasing gap between new languages and architectures Venerable and healthy area COOL overview # COOL: Classroom Object Oriented Language</description></item><item><title/><link>https://saligrama.io/notes/cs143/2022-04-05-lexical-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs143/2022-04-05-lexical-analysis/</guid><description>Lexical analysis # Goal: partition input strings into substrings; i.e.
if (i == j) z = 0; else z = 1; converts to
&amp;#34;if(i==j)\n\tz=0;\n\telse\n\tz=1&amp;#34; which we want to select the relevant tokens from.
Tokens # Tokens are a syntactic category
In English: noun, verb, adjective, etc. In programming languages: identifier, integer, keyword, whitespace, etc. A token class corresponds to a set of strings; e.g.
Identifier: strings of letters or digits, starting with a letter Integer: a non-empty string of digits Keyword: if, else, begin, etc.</description></item><item><title/><link>https://saligrama.io/notes/cs143/2022-04-07-lexical-analysis-implementation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs143/2022-04-07-lexical-analysis-implementation/</guid><description>Implementation of Lexical Analysis # Stages of code processing in lexical analysis:
Lexical Specification Regular Expressions NFA DFA Table-driven implementation of DFA Converting a lexical specification to a regular expression # Notation # Union: A + B = A | B Option: A + ε = A? Range: &amp;lsquo;a&amp;rsquo; + &amp;lsquo;b&amp;rsquo; + &amp;hellip; + &amp;lsquo;z&amp;rsquo; = [a-z] Excluded range: complement of [a-z] = ^[a-z] Steps # Write a regex for each token Number = digit + Keyword = 'if' + 'else' + .</description></item><item><title/><link>https://saligrama.io/notes/cs143/2022-04-12-parsing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs143/2022-04-12-parsing/</guid><description>Parsing # Parser functionality # Input: sequence of tokens from lexer Output: parse tree of the program (in practice, Abstract Syntax Tree) Parser distinguishes between valid and invalid strings of tokens Requires a language for describing valid strings of tokens Requires a method for distinguishing between valid and invalid strings of tokens e.g.
COOL syntax: if x = y then 1 else 2 fi Parser input (Lexer output): IF ID = ID THEN INT ELSE INT FI Parser output: Context-Free Grammars # Disadvantages of regular languages:</description></item><item><title/><link>https://saligrama.io/notes/cs143/2022-04-14-syntax-directed-translation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs143/2022-04-14-syntax-directed-translation/</guid><description>Error handling # Purpose of the compiler is to detect non-valid programs and to translate the valid ones Many kinds of possible errors: Lexical (detected by lexer) Syntax (detected by parser) Semantic (detected by type checker) Correctness (detected by tester/user) Syntax error handling # Error handler should Report errors accurately and clearly Recover from an error quickly Not slow down compilation of valid code Good error handling is not easy to achieve Panic Mode # Simplest, most popular method of error detection When an error is detected: Discard tokens until one with a clear role is found Continue from there These tokens are called synchronizing tokens Usually statement or expression terminators e.</description></item><item><title/><link>https://saligrama.io/notes/cs143/2022-04-19-top-down-parsing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs143/2022-04-19-top-down-parsing/</guid><description> Top-down parsing # Predictive parsers # Like recursive-descent, but parser can &amp;ldquo;predict&amp;rdquo; which production to use by looking at next few tokens (no backtracking) Predictive parsers accept LL(k) grammars First L: &amp;ldquo;left-to-right&amp;rdquo; input scan Second L: &amp;ldquo;leftmost derivation&amp;rdquo; k: &amp;ldquo;predict based on k tokens of lookahead&amp;rdquo; In practice: LL(1) LL(1) vs Recursive Descent # Recursive Descent: at each step, many choices of production to use Backtracking used to undo bad choices LL(1): at each step, only one choice of production When non-terminal A is leftmost in a derivation and next input t, either: Unique production A -&amp;gt; α to use No production to use (error state) Like a recursive descent variant but without backtracking Predictive parsing and left factoring # Example: consider grammar E -&amp;gt; T + E | T T -&amp;gt; int | int * T | ( E ) This is hard to predict because For T two productions start with int For E unclear how to predict Requires left-factoring the grammar Factor out common prefixes of productions: E -&amp;gt; T X X -&amp;gt; + E | ε T -&amp;gt; int Y | ( E ) Y -&amp;gt; * T | ε</description></item><item><title/><link>https://saligrama.io/notes/cs143/2022-04-26-semantic-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs143/2022-04-26-semantic-analysis/</guid><description>Semantic Analysis # Purpose of semantic analysis # Why separate semantic analysis?
Parsing cannot catch some errors Some language constructs are not context-free What does semantic analysis do? Checks constructs depending on language
coolc checks:
All identifiers are declared Types Inheritance relationships Classes defined only once Class methods only defined once Reserved identifiers are not misused etc. Types of semantic analysis checks # Scope # Matching identifier declarations with uses Important static analysis step in most languages, including COOL The scope of an identifier is the portion of a program in which that identifier is accessible Same identifier may refer to different things in different parts of the program An identifier may have restricted scope Static scope: depends only on program text, not run-time behavior (most languages, including COOL) Uses of an identifier refer to closest enclosing definition in program text Dynamic scope: depends on program execution (LISP, SNOBOL) Uses of an identifier refer to closest encloding binding in program execution In COOL: Not all kinds of identifiers follow most-closely-nested rule e.</description></item></channel></rss>