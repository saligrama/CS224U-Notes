<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CS 224U, Spring 2021 on Aditya's notes</title><link>https://saligrama.io/notes/cs224u/</link><description>Recent content in CS 224U, Spring 2021 on Aditya's notes</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://saligrama.io/notes/cs224u/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://saligrama.io/notes/cs224u/2021-03-29-course-overview/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs224u/2021-03-29-course-overview/</guid><description>Why Natural Language Understanding? # Perfect moment because the field is at or near peak Recent resurgence of interest Heavy industry use Still many weaknesses in existing systems Far from solved - still remain big breakthroughs to be found Course info # Course site: https://cs224u.stanford.edu
Code repo: https://github.com/cgpotts/cs224u
Topics # Vector-space models Sentiment analysis Contextual word representations Grounded language generation Relation extraction Natural Language Inference NLU and info. retrieval Adversarial testing Methods and metrics Assignments # Word relatedness Cross-domain sentiment analysis Generating color descriptions in context Each assignment culminates in a bakeoff - informal competition in which original models are entered</description></item><item><title/><link>https://saligrama.io/notes/cs224u/2021-03-31-vector-space-models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs224u/2021-03-31-vector-space-models/</guid><description>Distributed word representations # Meaning representations # Co-occurrence matrix:
Meaning can be present in such a matrix.
If a word co-occurs often with &amp;ldquo;excellent,&amp;rdquo; it likely is a positive word; if it co-occurs often with &amp;ldquo;terrible,&amp;rdquo; it likely denotes something negative Guiding hypothesis for vector-space models # The meaning of a word is derived from its use in a language. If two words have similar vectors in a co-occurrence matrix, they tend to have similar meanings (Turney and Pantel, 2010).</description></item><item><title/><link>https://saligrama.io/notes/cs224u/2021-04-12-sentiment-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://saligrama.io/notes/cs224u/2021-04-12-sentiment-analysis/</guid><description>Supervised sentiment analysis # Tokenization # Whitespace tokenizer # Very simple, just splits sentences into words by spacing. Example:
&amp;gt; whitespace_tokenizer(&amp;#34;The quick fox jumped over the lazy dog.&amp;#34;) [&amp;#39;The&amp;#39;, &amp;#39;quick&amp;#39;, &amp;#39;fox&amp;#39;, &amp;#39;jumped&amp;#39;, &amp;#39;over&amp;#39;, &amp;#39;the&amp;#39;, &amp;#39;lazy&amp;#39;, &amp;#39;dog.&amp;#39;] Note: simplest version will not take punctuation into account, which could be disruptive for using with VSMs
Sentiment-aware tokenizer # Ideally, a tokenizer would
Isolate emoticons Respects domain-specific markup (i.e., hashtags and @-mentions) Uses underlying markup Capture masked curses such as f@#$%ing Preserve meaningful capitalization Regularizes lengthening (i.</description></item></channel></rss>