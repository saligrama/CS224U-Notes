<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Distributed word representations # Meaning representations # Co-occurrence matrix:
Meaning can be present in such a matrix.
If a word co-occurs often with &ldquo;excellent,&rdquo; it likely is a positive word; if it co-occurs often with &ldquo;terrible,&rdquo; it likely denotes something negative Guiding hypothesis for vector-space models # The meaning of a word is derived from its use in a language. If two words have similar vectors in a co-occurrence matrix, they tend to have similar meanings (Turney and Pantel, 2010)."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content><meta property="og:description" content="Distributed word representations # Meaning representations # Co-occurrence matrix:
Meaning can be present in such a matrix.
If a word co-occurs often with &ldquo;excellent,&rdquo; it likely is a positive word; if it co-occurs often with &ldquo;terrible,&rdquo; it likely denotes something negative Guiding hypothesis for vector-space models # The meaning of a word is derived from its use in a language. If two words have similar vectors in a co-occurrence matrix, they tend to have similar meanings (Turney and Pantel, 2010)."><meta property="og:type" content="article"><meta property="og:url" content="https://saligrama.io/notes/cs224u/2021-03-31-vector-space-models/"><meta property="article:section" content="cs224u"><title>Vector Space Models | Aditya's notes</title><link rel=manifest href=/notes/manifest.json><link rel=icon href=/notes/favicon.png type=image/x-icon><link rel=stylesheet href=/notes/book.min.395a67680f48b8d23bbf267f26d0d1259e69554b2b704e371e8e15cbe656e05f.css integrity="sha256-OVpnaA9IuNI7vyZ/JtDRJZ5pVUsrcE43Ho4Vy+ZW4F8=" crossorigin=anonymous><script defer src=/notes/flexsearch.min.js></script>
<script defer src=/notes/en.search.min.20185cea7506331f915ab1ca9873ed3df866348f1939b82a7777023f528a3a47.js integrity="sha256-IBhc6nUGMx+RWrHKmHPtPfhmNI8ZObgqd3cCP1KKOkc=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/notes/><span>Aditya's notes</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-a88f46c31d1ebdf165810583424fda37 class=toggle>
<label for=section-a88f46c31d1ebdf165810583424fda37 class="flex justify-between"><a role=button>CS 103, Fall 2020</a></label><ul><li><a href=/notes/cs103/2020-09-16-set-theory/>Set Theory</a></li><li><a href=/notes/cs103/2020-09-18-indirect-proofs/>Indirect Proofs</a></li><li><a href=/notes/cs103/2020-09-18-mathematical-proofs/>Mathematical Proofs</a></li><li><a href=/notes/cs103/2020-09-26-first-order-logic/>First Order Logic</a></li><li><a href=/notes/cs103/2020-09-26-propositional-logic/>Propositional Logic</a></li><li><a href=/notes/cs103/2020-09-27-first-order-logic-continued/>First Order Logic Continued</a></li><li><a href=/notes/cs103/2020-09-30-binary-relations/>Binary Relations</a></li><li><a href=/notes/cs103/2020-10-01-binary-relations-continued/>Binary Relations Continued</a></li><li><a href=/notes/cs103/2020-10-04-functions/>Functions</a></li><li><a href=/notes/cs103/2020-10-10-cardinality/>Cardinality</a></li><li><a href=/notes/cs103/2020-10-11-graph-theory/>Graph Theory</a></li><li><a href=/notes/cs103/2020-10-17-pigeonhole-principle/>Pigeonhole Principle</a></li><li><a href=/notes/cs103/2020-10-18-induction/>Induction</a></li><li><a href=/notes/cs103/2020-10-19-induction-variants/>Induction Variants</a></li><li><a href=/notes/cs103/2020-10-20-computability-and-formal-languages/>Computability and Formal Languages</a></li><li><a href=/notes/cs103/2020-10-25-nondeterministic-finite-automata/>Nondeterministic Finite Automata</a></li><li><a href=/notes/cs103/2020-10-26-nfa-dfa-equivalence/>Nfa Dfa Equivalence</a></li><li><a href=/notes/cs103/2020-10-26-regular-expressions/>Regular Expressions</a></li><li><a href=/notes/cs103/2020-11-01-nonregular-languages/>Nonregular Languages</a></li><li><a href=/notes/cs103/2020-11-02-context-free-grammars/>Context Free Grammars</a></li><li><a href=/notes/cs103/2020-11-03-turing-machines/>Turing Machines</a></li><li><a href=/notes/cs103/2020-11-08-turing-machine-subroutines/>Turing Machine Subroutines</a></li><li><a href=/notes/cs103/2020-11-08-universal-turing-machine/>Universal Turing Machine</a></li><li><a href=/notes/cs103/2020-11-08-unsolvable-problems/>Unsolvable Problems</a></li><li><a href=/notes/cs103/2020-11-14-unsolvable-problems-continued/>Unsolvable Problems Continued</a></li></ul></li><li><input type=checkbox id=section-cf13475a7a80a5dd57b5a55dce73d171 class=toggle>
<label for=section-cf13475a7a80a5dd57b5a55dce73d171 class="flex justify-between"><a role=button>CS 107, Fall 2020</a></label><ul><li><a href=/notes/cs107/2020-09-18-integer-representations/>Integer Representations</a></li><li><a href=/notes/cs107/2020-09-21-bitwise-operations/>Bitwise Operations</a></li><li><a href=/notes/cs107/2020-09-25-c-chars-and-strings/>C Chars and Strings</a></li><li><a href=/notes/cs107/2020-09-28-more-c-strings/>More C Strings</a></li><li><a href=/notes/cs107/2020-10-02-pointers-arrays/>Pointers Arrays</a></li><li><a href=/notes/cs107/2020-10-05-stack-and-heap/>Stack and Heap</a></li><li><a href=/notes/cs107/2020-10-09-c-generics/>C Generics</a></li><li><a href=/notes/cs107/2020-10-12-function-pointers/>Function Pointers</a></li><li><a href=/notes/cs107/2020-10-16-assembly/>Assembly</a></li><li><a href=/notes/cs107/2020-10-19-assembly-arithmetic-logic/>Assembly Arithmetic Logic</a></li><li><a href=/notes/cs107/2020-10-23-assembly-control-flow/>Assembly Control Flow</a></li><li><a href=/notes/cs107/2020-10-26-assembly-function-calls-and-return-stack/>Assembly Function Calls and Return Stack</a></li><li><a href=/notes/cs107/2020-10-30-heap-management/>Heap Management</a></li><li><a href=/notes/cs107/2020-11-09-program-optimization/>Program Optimization</a></li></ul></li><li><input type=checkbox id=section-4e3bc6e2f7a0feae33c3e43356d49c80 class=toggle>
<label for=section-4e3bc6e2f7a0feae33c3e43356d49c80 class="flex justify-between"><a role=button>CS 110L, Spring 2021</a></label><ul><li><a href=/notes/cs110l/2021-03-30-course-overview/>Course Overview</a></li><li><a href=/notes/cs110l/2021-04-01-fixing-c/>Fixing C</a></li><li><a href=/notes/cs110l/2021-04-06-intro-to-rust/>Intro to Rust</a></li><li><a href=/notes/cs110l/2021-04-08-ownership/>Ownership</a></li><li><a href=/notes/cs110l/2021-04-13-error-handling/>Error Handling</a></li><li><a href=/notes/cs110l/2021-04-22-traits/>Traits</a></li><li><a href=/notes/cs110l/2021-04-27-generics/>Generics</a></li><li><a href=/notes/cs110l/2021-04-29-multiprocessing/>Multiprocessing</a></li></ul></li><li><input type=checkbox id=section-23e7773af736437c02202412a988f2db class=toggle>
<label for=section-23e7773af736437c02202412a988f2db class="flex justify-between"><a role=button>CS 111, Spring 2021</a></label><ul><li><a href=/notes/cs111/2021-03-31-threads-and-dispatching/>Threads and Dispatching</a></li><li><a href=/notes/cs111/2021-04-02-concurrency/>Concurrency</a></li><li><a href=/notes/cs111/2021-04-05-synchronization/>Synchronization</a></li><li><a href=/notes/cs111/2021-04-07-shared-memory-and-condition-variables-and-locks/>Shared Memory and Condition Variables and Locks</a></li><li><a href=/notes/cs111/2021-04-09-lock-implementation-and-deadlocking/>Lock Implementation and Deadlocking</a></li><li><a href=/notes/cs111/2021-04-12-scheduling/>Scheduling</a></li><li><a href=/notes/cs111/2021-04-14-multiprocessing/>Multiprocessing</a></li><li><a href=/notes/cs111/2021-04-16-linking/>Linking</a></li><li><a href=/notes/cs111/2021-04-19-storage-management/>Storage Management</a></li><li><a href=/notes/cs111/2021-04-21-virtual-memory/>Virtual Memory</a></li><li><a href=/notes/cs111/2021-04-23-dynamic-address-translation/>Dynamic Address Translation</a></li><li><a href=/notes/cs111/2021-04-26-segmentation-and-paging/>Segmentation and Paging</a></li><li><a href=/notes/cs111/2021-04-30-demand-paging/>Demand Paging</a></li><li><a href=/notes/cs111/2021-05-05-disks/>Disks</a></li><li><a href=/notes/cs111/2021-05-07-file-systems/>File Systems</a></li><li><a href=/notes/cs111/2021-05-10-realworld-filesystem-structures/>Realworld Filesystem Structures</a></li><li><a href=/notes/cs111/2021-05-12-directories/>Directories</a></li><li><a href=/notes/cs111/2021-05-14-crash-recovery/>Crash Recovery</a></li><li><a href=/notes/cs111/2021-05-19-protection/>Protection</a></li><li><a href=/notes/cs111/2021-05-24-flash-memory/>Flash Memory</a></li><li><a href=/notes/cs111/2021-05-28-virtual-machines/>Virtual Machines</a></li></ul></li><li><input type=checkbox id=section-a586b190ebf0a4874cd21a1d76743261 class=toggle>
<label for=section-a586b190ebf0a4874cd21a1d76743261 class="flex justify-between"><a role=button>CS 143, Spring 2022</a></label><ul><li><a href=/notes/cs143/2022-03-29-intro/>Intro</a></li><li><a href=/notes/cs143/2022-03-31-language-design-and-cool/>Language Design and Cool</a></li><li><a href=/notes/cs143/2022-04-05-lexical-analysis/>Lexical Analysis</a></li><li><a href=/notes/cs143/2022-04-07-lexical-analysis-implementation/>Lexical Analysis Implementation</a></li><li><a href=/notes/cs143/2022-04-12-parsing/>Parsing</a></li><li><a href=/notes/cs143/2022-04-14-syntax-directed-translation/>Syntax Directed Translation</a></li><li><a href=/notes/cs143/2022-04-19-top-down-parsing/>Top Down Parsing</a></li><li><a href=/notes/cs143/2022-04-26-semantic-analysis/>Semantic Analysis</a></li></ul></li><li><input type=checkbox id=section-37836de7a703e433b2642097d511f482 class=toggle>
<label for=section-37836de7a703e433b2642097d511f482 class="flex justify-between"><a role=button>CS 149, Fall 2022</a></label><ul><li><a href=/notes/cs149/2022-09-27-intro/>Intro</a></li><li><a href=/notes/cs149/2022-09-29-modern-multicore-processors/>Modern Multicore Processors</a></li><li><a href=/notes/cs149/2022-10-04-parallel-abstractions/>Parallel Abstractions</a></li><li><a href=/notes/cs149/2022-10-06-parallel-models/>Parallel Models</a></li><li><a href=/notes/cs149/2022-10-11-work-distribution-and-scheduling/>Work Distribution and Scheduling</a></li><li><a href=/notes/cs149/2022-10-13-locality-communication-and-contention/>Locality Communication and Contention</a></li><li><a href=/notes/cs149/2022-10-18-gpu-architecture-and-cuda/>Gpu Architecture and Cuda</a></li><li><a href=/notes/cs149/2022-10-20-data-parallel-architecture/>Data Parallel Architecture</a></li><li><a href=/notes/cs149/2022-10-25-spark/>Spark</a></li><li><a href=/notes/cs149/2022-10-27-cache-coherence/>Cache Coherence</a></li><li><a href=/notes/cs149/2022-11-01-memory-consistency/>Memory Consistency</a></li><li><a href=/notes/cs149/2022-11-03-lock-implementation-and-lock-free-programming/>Lock Implementation and Lock Free Programming</a></li><li><a href=/notes/cs149/2022-11-10-transactional-memory/>Transactional Memory</a></li><li><a href=/notes/cs149/2022-11-29-heterogeneous-processing-and-domain-specific-languages/>Heterogeneous Processing and Domain Specific Languages</a></li><li><a href=/notes/cs149/2022-12-06-asics-and-fpgas/>Asics and Fpgas</a></li></ul></li><li><input type=checkbox id=section-4f9fa520660f975442d4640415905b3c class=toggle>
<label for=section-4f9fa520660f975442d4640415905b3c class="flex justify-between"><a role=button>CS 154, Fall 2021</a></label><ul><li><a href=/notes/cs154/2021-09-28-finite-automata/>Finite Automata</a></li><li><a href=/notes/cs154/2021-10-05-pumping-lemma-and-myhill-nerode/>Pumping Lemma and Myhill Nerode</a></li><li><a href=/notes/cs154/2021-10-12-streaming-algorithms-and-turing-machines/>Streaming Algorithms and Turing Machines</a></li></ul></li><li><input type=checkbox id=section-d24cd7d7d21fe73135d596a09b50887f class=toggle>
<label for=section-d24cd7d7d21fe73135d596a09b50887f class="flex justify-between"><a role=button>CS 155, Spring 2022</a></label><ul><li><a href=/notes/cs155/2022-03-28-intro/>Intro</a></li><li><a href=/notes/cs155/2022-03-30-control-hijacking/>Control Hijacking</a></li><li><a href=/notes/cs155/2022-04-04-control-hijacking-defenses/>Control Hijacking Defenses</a></li><li><a href=/notes/cs155/2022-04-06-security-principles/>Security Principles</a></li><li><a href=/notes/cs155/2022-04-11-isolation-and-sandboxing/>Isolation and Sandboxing</a></li><li><a href=/notes/cs155/2022-04-13-vuln-finding/>Vuln Finding</a></li><li><a href=/notes/cs155/2022-04-18-web-security/>Web Security</a></li><li><a href=/notes/cs155/2022-04-20-web-attacks/>Web Attacks</a></li><li><a href=/notes/cs155/2022-04-25-web-defenses/>Web Defenses</a></li><li><a href=/notes/cs155/2022-05-04-processor-security/>Processor Security</a></li><li><a href=/notes/cs155/2022-05-09-internet-protocol-security/>Internet Protocol Security</a></li></ul></li><li><input type=checkbox id=section-471622039e8d87cd8d642483c8d218b8 class=toggle>
<label for=section-471622039e8d87cd8d642483c8d218b8 class="flex justify-between"><a role=button>CS 161, Winter 2022</a></label><ul><li><a href=/notes/cs161/2022-01-03-intro/>Intro</a></li><li><a href=/notes/cs161/2022-01-05-worst-case-and-asymptotic-analysis/>Worst Case and Asymptotic Analysis</a></li><li><a href=/notes/cs161/2022-01-10-recurrence-relations/>Recurrence Relations</a></li><li><a href=/notes/cs161/2022-01-12-median-and-selection/>Median and Selection</a></li><li><a href=/notes/cs161/2022-01-19-randomized-algorithms-and-quicksort/>Randomized Algorithms and Quicksort</a></li><li><a href=/notes/cs161/2022-01-24-sorting-lower-bounds/>Sorting Lower Bounds</a></li><li><a href=/notes/cs161/2022-01-26-binary-search-trees/>Binary Search Trees</a></li><li><a href=/notes/cs161/2022-01-31-hashing/>Hashing</a></li><li><a href=/notes/cs161/2022-02-02-graphs-and-graph-search/>Graphs and Graph Search</a></li><li><a href=/notes/cs161/2022-02-07-strongly-connected-components/>Strongly Connected Components</a></li><li><a href=/notes/cs161/2022-02-09-weighted-graphs-and-dijkstra/>Weighted Graphs and Dijkstra</a></li><li><a href=/notes/cs161/2022-02-14-dynamic-programming/>Dynamic Programming</a></li><li><a href=/notes/cs161/2022-02-16-dynamic-programming-applications/>Dynamic Programming Applications</a></li><li><a href=/notes/cs161/2022-02-23-greedy-algorithms/>Greedy Algorithms</a></li><li><a href=/notes/cs161/2022-02-28-minimum-spanning-trees/>Minimum Spanning Trees</a></li></ul></li><li><input type=checkbox id=section-0794dc87987599843ba69a8ea82e9b6a class=toggle checked>
<label for=section-0794dc87987599843ba69a8ea82e9b6a class="flex justify-between"><a role=button>CS 224U, Spring 2021</a></label><ul><li><a href=/notes/cs224u/2021-03-29-course-overview/>Course Overview</a></li><li><a href=/notes/cs224u/2021-03-31-vector-space-models/ class=active>Vector Space Models</a></li><li><a href=/notes/cs224u/2021-04-12-sentiment-analysis/>Sentiment Analysis</a></li></ul></li><li><input type=checkbox id=section-efae8264f5fe410feb1b40be6f99baea class=toggle>
<label for=section-efae8264f5fe410feb1b40be6f99baea class="flex justify-between"><a role=button>CS 229, Fall 2021</a></label><ul><li><a href=/notes/cs229/2021-09-21-intro/>Intro</a></li><li><a href=/notes/cs229/2021-09-23-supervised-learning-setup/>Supervised Learning Setup</a></li><li><a href=/notes/cs229/2021-09-28-logistic-regression/>Logistic Regression</a></li><li><a href=/notes/cs229/2021-09-30-generalized-linear-models/>Generalized Linear Models</a></li><li><a href=/notes/cs229/2021-10-05-generative-learning-algorithms/>Generative Learning Algorithms</a></li><li><a href=/notes/cs229/2021-10-07-naive-bayes/>Naive Bayes</a></li><li><a href=/notes/cs229/2021-10-12-kernel-methods-and-svm/>Kernel Methods and Svm</a></li><li><a href=/notes/cs229/2021-10-14-deep-learning/>Deep Learning</a></li><li><a href=/notes/cs229/2021-10-19-deep-learning-optimization/>Deep Learning Optimization</a></li><li><a href=/notes/cs229/2021-10-21-model-selection/>Model Selection</a></li></ul></li><li><input type=checkbox id=section-58493bdbfe80396f07f44c40ecf068c8 class=toggle>
<label for=section-58493bdbfe80396f07f44c40ecf068c8 class="flex justify-between"><a role=button>CS 249I, Winter 2023</a></label><ul><li><a href=/notes/cs249i/2023-01-09-internet-players/>Internet Players</a></li><li><a href=/notes/cs249i/2023-01-18-modern-routing-practices/>Modern Routing Practices</a></li><li><a href=/notes/cs249i/2023-01-23-last-mile-access/>Last Mile Access</a></li><li><a href=/notes/cs249i/2023-01-25-host-and-network-addressing/>Host and Network Addressing</a></li><li><a href=/notes/cs249i/2023-01-30-domain-name-system/>Domain Name System</a></li><li><a href=/notes/cs249i/2023-02-06-internet-governance/>Internet Governance</a></li><li><a href=/notes/cs249i/2023-02-08-modern-web-protocols/>Modern Web Protocols</a></li><li><a href=/notes/cs249i/2023-02-13-tls-and-webpki/>Tls and Webpki</a></li><li><a href=/notes/cs249i/2023-02-13-web-content/>Web Content</a></li><li><a href=/notes/cs249i/2023-02-22-internet-crime/>Internet Crime</a></li><li><a href=/notes/cs249i/2023-02-27-middleboxes-and-nat-and-https-interception/>Middleboxes and Nat and Https Interception</a></li><li><a href=/notes/cs249i/2023-03-01-modern-cryptography/>Modern Cryptography</a></li><li><a href=/notes/cs249i/2023-03-06-content-delivery/>Content Delivery</a></li></ul></li><li><input type=checkbox id=section-292ea4e126876f1048e61c4dc744546c class=toggle>
<label for=section-292ea4e126876f1048e61c4dc744546c class="flex justify-between"><a role=button>CS 251, Fall 2022</a></label><ul><li><a href=/notes/cs251/2022-09-26-intro/>Intro</a></li><li><a href=/notes/cs251/2022-09-28-bitcoin-mechanics/>Bitcoin Mechanics</a></li><li><a href=/notes/cs251/2022-10-03-bitcoin-scripts-and-wallets/>Bitcoin Scripts and Wallets</a></li><li><a href=/notes/cs251/2022-10-05-consensus/>Consensus</a></li><li><a href=/notes/cs251/2022-10-10-internet-consensus/>Internet Consensus</a></li><li><a href=/notes/cs251/2022-10-17-ethereum/>Ethereum</a></li><li><a href=/notes/cs251/2022-10-19-solidity/>Solidity</a></li><li><a href=/notes/cs251/2022-11-02-legal-aspects-and-regulation/>Legal Aspects and Regulation</a></li><li><a href=/notes/cs251/2022-11-07-privacy-and-deanonymization-and-mixing/>Privacy and Deanonymization and Mixing</a></li><li><a href=/notes/cs251/2022-11-09-privacy-via-zk-snarks/>Privacy via Zk Snarks</a></li></ul></li><li><input type=checkbox id=section-98d861db134658b3e020a9d74c50ad24 class=toggle>
<label for=section-98d861db134658b3e020a9d74c50ad24 class="flex justify-between"><a role=button>CS 255, Winter 2022</a></label><ul><li><a href=/notes/cs255/2022-01-03-intro/>Intro</a></li><li><a href=/notes/cs255/2022-01-05-stream-ciphers/>Stream Ciphers</a></li><li><a href=/notes/cs255/2022-01-10-block-ciphers/>Block Ciphers</a></li><li><a href=/notes/cs255/2022-01-12-pseudorandom-functions/>Pseudorandom Functions</a></li><li><a href=/notes/cs255/2022-01-19-data-integrity-and-macs/>Data Integrity and Macs</a></li><li><a href=/notes/cs255/2022-01-24-collision-resistance/>Collision Resistance</a></li><li><a href=/notes/cs255/2022-01-26-authenticated-encryption/>Authenticated Encryption</a></li><li><a href=/notes/cs255/2022-01-31-key-management/>Key Management</a></li><li><a href=/notes/cs255/2022-02-02-key-exchange-math/>Key Exchange Math</a></li><li><a href=/notes/cs255/2022-02-07-public-key-encryption/>Public Key Encryption</a></li><li><a href=/notes/cs255/2022-02-09-pke-schemes/>Pke Schemes</a></li><li><a href=/notes/cs255/2022-02-14-digital-signatures/>Digital Signatures</a></li><li><a href=/notes/cs255/2022-02-16-certificates/>Certificates</a></li><li><a href=/notes/cs255/2022-02-23-id-protocols/>Id Protocols</a></li><li><a href=/notes/cs255/2022-02-28-key-exchange-protocols/>Key Exchange Protocols</a></li><li><a href=/notes/cs255/2022-03-02-zero-knowledge-protocols/>Zero Knowledge Protocols</a></li><li><a href=/notes/cs255/2022-03-07-quantum-cryptography/>Quantum Cryptography</a></li></ul></li><li><input type=checkbox id=section-3c4550884ed49f470e55fabac7077d16 class=toggle>
<label for=section-3c4550884ed49f470e55fabac7077d16 class="flex justify-between"><a role=button>Cs153</a></label><ul><li><a href=/notes/cs153/2023-01-12-intro/>Intro</a></li></ul></li><li><input type=checkbox id=section-568ed1bc8289796d56a6d06a22d7eb40 class=toggle>
<label for=section-568ed1bc8289796d56a6d06a22d7eb40 class="flex justify-between"><a role=button>INTLPOL 268, Fall 2021</a></label><ul><li><a href=/notes/intlpol268/2021-09-20-intro/>Intro</a></li><li><a href=/notes/intlpol268/2021-09-22-legal-intro-and-electronic-communications-privacy-act/>Legal Intro and Electronic Communications Privacy Act</a></li><li><a href=/notes/intlpol268/2021-09-27-web-requests-and-attacks/>Web Requests and Attacks</a></li><li><a href=/notes/intlpol268/2021-09-29-ecpa-for-private-actors/>Ecpa for Private Actors</a></li><li><a href=/notes/intlpol268/2021-10-04-cyberattacks/>Cyberattacks</a></li><li><a href=/notes/intlpol268/2021-10-06-computer-fraud-and-abuse-act/>Computer Fraud and Abuse Act</a></li><li><a href=/notes/intlpol268/2021-10-11-network-security/>Network Security</a></li><li><a href=/notes/intlpol268/2021-10-13-cfaa-dmca-and-security-research/>Cfaa Dmca and Security Research</a></li><li><a href=/notes/intlpol268/2021-10-20-data-security-laws/>Data Security Laws</a></li><li><a href=/notes/intlpol268/2021-10-25-corporate-intrusion/>Corporate Intrusion</a></li><li><a href=/notes/intlpol268/2021-10-27-ransomware-and-foreign-hackers/>Ransomware and Foreign Hackers</a></li><li><a href=/notes/intlpol268/2021-11-01-cryptography/>Cryptography</a></li><li><a href=/notes/intlpol268/2021-11-03-cyber-conflict/>Cyber Conflict</a></li><li><a href=/notes/intlpol268/2021-11-08-dark-web-and-cryptocurrencies/>Dark Web and Cryptocurrencies</a></li><li><a href=/notes/intlpol268/2021-11-10-encryption-and-technical-assistance/>Encryption and Technical Assistance</a></li><li><a href=/notes/intlpol268/2021-11-15-malware/>Malware</a></li><li><a href=/notes/intlpol268/2021-11-17-government-hacking/>Government Hacking</a></li><li><a href=/notes/intlpol268/2021-11-29-new-frontiers/>New Frontiers</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/notes/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Vector Space Models</strong>
<label for=toc-control><img src=/notes/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#distributed-word-representations>Distributed word representations</a><ul><li><a href=#meaning-representations>Meaning representations</a></li><li><a href=#guiding-hypothesis-for-vector-space-models>Guiding hypothesis for vector-space models</a></li><li><a href=#feature-representations-of-data>Feature representations of data</a></li><li><a href=#what-do-we-define-co-occurrence-as>What do we define co-occurrence as?</a></li><li><a href=#constructing-data>Constructing data</a></li><li><a href=#matrix-design>Matrix design</a><ul><li><a href=#word-x-word>word x word</a></li><li><a href=#word-x-document>word x document</a></li><li><a href=#word-x-discourse-context>word x discourse context</a></li><li><a href=#other-designs>Other designs</a></li></ul></li><li><a href=#vector-comparison-similarity>Vector comparison (similarity)</a><ul><li><a href=#euclidean>Euclidean</a></li><li><a href=#cosine>Cosine</a></li><li><a href=#other-metrics>Other metrics</a></li></ul></li><li><a href=#reweighting>Reweighting</a><ul><li><a href=#normalization>Normalization</a></li><li><a href=#observedexpected>Observed/Expected</a></li><li><a href=#pointwise-mutual-information-pmi>Pointwise Mutual Information (PMI)</a></li><li><a href=#positive-pmi>Positive PMI</a></li><li><a href=#tf-idf>TF-IDF</a></li></ul></li><li><a href=#dimensionality-reduction>Dimensionality reduction</a><ul><li><a href=#latent-semantic-analysis>Latent Semantic Analysis</a></li><li><a href=#autoencoders>Autoencoders</a></li><li><a href=#glove>GloVe</a></li></ul></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=distributed-word-representations>Distributed word representations
<a class=anchor href=#distributed-word-representations>#</a></h1><h2 id=meaning-representations>Meaning representations
<a class=anchor href=#meaning-representations>#</a></h2><p>Co-occurrence matrix:</p><p><img src=/notes/images/cs224u/2021-03-31-co-occurrence-matrix.png alt="Co-occurrence matrix"></p><p>Meaning can be present in such a matrix.</p><ul><li>If a word co-occurs often with &ldquo;excellent,&rdquo; it likely is a positive word; if it co-occurs often with &ldquo;terrible,&rdquo; it likely denotes something negative</li></ul><h2 id=guiding-hypothesis-for-vector-space-models>Guiding hypothesis for vector-space models
<a class=anchor href=#guiding-hypothesis-for-vector-space-models>#</a></h2><p>The meaning of a word is derived from its use in a language. If two words have similar vectors in a co-occurrence matrix, they tend to have similar meanings (<a href=https://arxiv.org/abs/1003.1141>Turney and Pantel, 2010</a>).</p><h2 id=feature-representations-of-data>Feature representations of data
<a class=anchor href=#feature-representations-of-data>#</a></h2><ul><li><em>the movie was horrible</em> becomes [4, 0, 0.25] (4 words, 0 proper names, 0.25 concentration of negative words)</li><li>Reduces noisy data to restricted feature set</li></ul><h2 id=what-do-we-define-co-occurrence-as>What do we define co-occurrence as?
<a class=anchor href=#what-do-we-define-co-occurrence-as>#</a></h2><p>For a sentence, e.g. <em>from swerve of shore to bend of bay, brings</em></p><p>Consider the word &ldquo;to&rdquo;</p><ul><li>Window: how many words around &ldquo;to&rdquo; (in both directions) do we want to focus on?</li><li>Scaling: how to weight words in the window?<ul><li>Flat: treat everything equally</li><li>Inverse: word is weighted 1/n if it is distance n from the target word</li></ul></li></ul><p>Larger, flatter windows capture more semantic information, whereas smaller, more scaled windows capture more syntactic information</p><p>Can also consider different unit sizes - words, sentences, etc</p><h2 id=constructing-data>Constructing data
<a class=anchor href=#constructing-data>#</a></h2><ul><li>Tokenization</li><li>Annotation</li><li>Tagging</li><li>Parsing</li><li>Feature selection</li></ul><h2 id=matrix-design>Matrix design
<a class=anchor href=#matrix-design>#</a></h2><h3 id=word-x-word>word x word
<a class=anchor href=#word-x-word>#</a></h3><ul><li>Rows and columns represent individual words</li><li>Value <code>a_ij</code> in a matrix represents how many times words <code>i</code> and <code>j</code> co-occur with each other in a given set of documents</li><li>Very dense (lots of nonzero entries)! Density increases with more documents in the corpus</li><li>Dimensionality remains fixed as we bring in new data as long as we pre-decide on vocabulary</li></ul><h3 id=word-x-document>word x document
<a class=anchor href=#word-x-document>#</a></h3><ul><li>Rows represent words; columns represent documents</li><li>Value <code>a_ij</code> in a matrix represents how many times word <code>i</code> occurs in document <code>j</code></li><li>Very sparse: may be hard to compute certain operations, but easy storage</li></ul><h3 id=word-x-discourse-context>word x discourse context
<a class=anchor href=#word-x-discourse-context>#</a></h3><ul><li>Rows represent words; columns represent discourse context labels<ul><li>Labels are assigned by human annotators based on what type of context the sentence is (i.e., acceptance dialogue, rejecting part of previous statement, phrase completion, etc)</li></ul></li><li>Value <code>a_ij</code> in a matrix represents how many times word <code>i</code> occurs in discource context <code>j</code></li></ul><h3 id=other-designs>Other designs
<a class=anchor href=#other-designs>#</a></h3><ul><li>word x search proximity</li><li>adj x modified noun</li><li>word x dependency relations</li></ul><p>Note: Models like GloVe and word2vec provide packaged solutions that pre-chose from these design choices.</p><h2 id=vector-comparison-similarity>Vector comparison (similarity)
<a class=anchor href=#vector-comparison-similarity>#</a></h2><p>Within the context of this example:</p><p><img src=/notes/images/cs224u/2021-03-31-comparison-example.png alt=Example></p><p>Note that B and C are close in distance (frequency info), but A and B have a similar bias (syntactic/semantic info)</p><h3 id=euclidean>Euclidean
<a class=anchor href=#euclidean>#</a></h3><p>For vectors <code>u</code>, <code>v</code> of <code>n</code> dimensions:</p><p><img src=https://latex.codecogs.com/png.latex?%5Cbg_white%20euc%28u%2C%20v%29%20%3D%20%5Csqrt%7B%5Csum_%7Bi%3D1%7D%5En%20%7Cu_i%20-%20v_i%7C%5E2%7D alt=euc_eq></p><p>This measures the straight-line distance between <code>u</code> and <code>v</code> capturing the pure distance aspect of similarity</p><p>Note: Length normalization</p><p><img src=/notes/images/cs224u/2021-03-31-length-norm.png alt="Length norm"></p><p>This captures the bias aspect of similarity</p><h3 id=cosine>Cosine
<a class=anchor href=#cosine>#</a></h3><p>For vectors <code>u</code>, <code>v</code> of <code>n</code> dimensions:</p><p><img src=https://latex.codecogs.com/png.latex?%5Cbg_white%20cosdist%28u%2C%20v%29%20%3D%201%20-%20%5Cfrac%7Bu_i%5ET%20v_i%7D%7B%7C%7Cu%7C%7C_2%20%7C%7Cv%7C%7C_2%7D alt=cos_eq></p><ul><li>Division by the length effectively normalizes vectors</li><li>Captures the bias aspect of similarity</li><li>Not considered a proper distance metric because it fails the triangle inequality; however, the following does:</li></ul><p><img src=https://latex.codecogs.com/png.latex?%5Cbg_white%20newcosdist%28u%2C%20v%29%20%3D%20%5Cfrac%7B%5Ccos%5E%7B-1%7D%5Cleft%28%5Cfrac%7Bu_i%5ET%20v_i%7D%7B%7C%7Cu%7C%7C_2%20%7C%7Cv%7C%7C_2%7D%5Cright%29%7D%7B%5Cpi%7D alt=newcos_eq></p><ul><li>But the correlation between these two metrics is nearly perfect, so in practice, use the simpler one</li></ul><h3 id=other-metrics>Other metrics
<a class=anchor href=#other-metrics>#</a></h3><ul><li>Matching</li><li>Dice</li><li>Jaccard</li><li>KL (distance between probability distributions)</li><li>Overlap</li></ul><h2 id=reweighting>Reweighting
<a class=anchor href=#reweighting>#</a></h2><p>Goal: Amplify important data useful for generalization, because raw counts/frequency are poor proxy for semantic information</p><h3 id=normalization>Normalization
<a class=anchor href=#normalization>#</a></h3><ul><li>L2 norming (see above)</li><li>Probability distribution: divide values by sum of all values</li></ul><h3 id=observedexpected>Observed/Expected
<a class=anchor href=#observedexpected>#</a></h3><p><img src=/notes/images/cs224u/2021-03-31-observed-expected.png alt=Observed/Expected></p><p><strong>Intuition</strong>: Keeps words in idioms co-occurring more than expected; other word pairs co-occur less than expected</p><h3 id=pointwise-mutual-information-pmi>Pointwise Mutual Information (PMI)
<a class=anchor href=#pointwise-mutual-information-pmi>#</a></h3><p><img src="https://latex.codecogs.com/png.latex?%5cbg_white%20pmi%28X,%20i,%20j%29%20=%20ln%5cleft%28%5cfrac%7bX_%7bij%7d%7d%7b%5ctext%7bexpected%7d%28X,%20i,%20j%29%7d%5cright%29%20=%20ln%5cleft%28%5cfrac%7bP%28X_%7bij%7d%29%7d%7bP%28X_%7bi*%7d%29P%28X_%7b*j%7d%29%7d%5cright%29" alt=PMI></p><p>This is the log of observed count divided by expected count.</p><h3 id=positive-pmi>Positive PMI
<a class=anchor href=#positive-pmi>#</a></h3><p>PMI undefined when <code>X_{ij} = 0</code>. So:</p><p><img src="https://latex.codecogs.com/png.latex?%5cbg_white%20ppmi%28X,%20i,%20j%29%20=%20max%280,%20pmi%28X,i,j%29%29" alt=PPMI></p><h3 id=tf-idf>TF-IDF
<a class=anchor href=#tf-idf>#</a></h3><p>For a corpus of documents D:</p><p><img src=/notes/images/cs224u/2021-03-31-tf-idf.png alt=TF-IDF></p><h2 id=dimensionality-reduction>Dimensionality reduction
<a class=anchor href=#dimensionality-reduction>#</a></h2><h3 id=latent-semantic-analysis>Latent Semantic Analysis
<a class=anchor href=#latent-semantic-analysis>#</a></h3><ul><li>Also known as Trucated Singular Value Decomposition (Truncated SVD)</li><li>Standard baseline, difficult to beat</li></ul><p>Intuition:</p><ul><li>Fitting a linear model onto data encourages dimensionality reduction (since we can project data onto the model); this captures greatest source of variation in the data</li><li>We can continue adding linear models to capture other sources of variation</li></ul><p>Method:</p><p>Any matrix of real numbers can be written as</p><p><img src="https://latex.codecogs.com/png.latex?%5cbg_white%20A%20=%20TSD%5eT" alt=SVD></p><p>where <code>S</code> is a diagonal matrix of singular values and <code>T</code> and <code>D^T</code> are orthogonal. In NLP, <code>T</code> is the term matrix and <code>D^T</code> is the document matrix.</p><p>Dimensionality reduction comes from being selective about which singular values and terms to include (i.e., capturing only a few sources of variation in the data).</p><h3 id=autoencoders>Autoencoders
<a class=anchor href=#autoencoders>#</a></h3><ul><li>Flexible class of deep learning architectures for learning reduced dimensional representations</li></ul><p>Basic autoencoder model:</p><p><img src=/notes/images/cs224u/2021-03-31-autoencoder.png alt=Autoencoder></p><h3 id=glove>GloVe
<a class=anchor href=#glove>#</a></h3><ul><li>Goal is to learn vectors for words such that their dot product is proportional to their log probability of co-occurrence</li></ul><p><img src=/notes/images/cs224u/2021-03-31-glove-objective.png alt="GloVe Objective"></p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#distributed-word-representations>Distributed word representations</a><ul><li><a href=#meaning-representations>Meaning representations</a></li><li><a href=#guiding-hypothesis-for-vector-space-models>Guiding hypothesis for vector-space models</a></li><li><a href=#feature-representations-of-data>Feature representations of data</a></li><li><a href=#what-do-we-define-co-occurrence-as>What do we define co-occurrence as?</a></li><li><a href=#constructing-data>Constructing data</a></li><li><a href=#matrix-design>Matrix design</a><ul><li><a href=#word-x-word>word x word</a></li><li><a href=#word-x-document>word x document</a></li><li><a href=#word-x-discourse-context>word x discourse context</a></li><li><a href=#other-designs>Other designs</a></li></ul></li><li><a href=#vector-comparison-similarity>Vector comparison (similarity)</a><ul><li><a href=#euclidean>Euclidean</a></li><li><a href=#cosine>Cosine</a></li><li><a href=#other-metrics>Other metrics</a></li></ul></li><li><a href=#reweighting>Reweighting</a><ul><li><a href=#normalization>Normalization</a></li><li><a href=#observedexpected>Observed/Expected</a></li><li><a href=#pointwise-mutual-information-pmi>Pointwise Mutual Information (PMI)</a></li><li><a href=#positive-pmi>Positive PMI</a></li><li><a href=#tf-idf>TF-IDF</a></li></ul></li><li><a href=#dimensionality-reduction>Dimensionality reduction</a><ul><li><a href=#latent-semantic-analysis>Latent Semantic Analysis</a></li><li><a href=#autoencoders>Autoencoders</a></li><li><a href=#glove>GloVe</a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>