<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Spark: Distributed Computing on a Cluster # Cluster environment # Main idea: distributed computing, programming with 10k-100k cares How to ensure no data loss in case of failure of some system component? Programming model: data-parallel operations (e.g. Map and Reduce) Goal: make data-parallel operations Scalable (100ks of cores) Fault-tolerant (ensure no data loss in case of failure) Efficient (optimize system perf. with efficient use of memory) Why use a cluster?"><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content><meta property="og:description" content="Spark: Distributed Computing on a Cluster # Cluster environment # Main idea: distributed computing, programming with 10k-100k cares How to ensure no data loss in case of failure of some system component? Programming model: data-parallel operations (e.g. Map and Reduce) Goal: make data-parallel operations Scalable (100ks of cores) Fault-tolerant (ensure no data loss in case of failure) Efficient (optimize system perf. with efficient use of memory) Why use a cluster?"><meta property="og:type" content="article"><meta property="og:url" content="https://saligrama.io/notes/cs149/2022-10-25-spark/"><meta property="article:section" content="cs149"><title>Spark | Aditya's notes</title><link rel=manifest href=/notes/manifest.json><link rel=icon href=/notes/favicon.png type=image/x-icon><link rel=stylesheet href=/notes/book.min.395a67680f48b8d23bbf267f26d0d1259e69554b2b704e371e8e15cbe656e05f.css integrity="sha256-OVpnaA9IuNI7vyZ/JtDRJZ5pVUsrcE43Ho4Vy+ZW4F8=" crossorigin=anonymous><script defer src=/notes/flexsearch.min.js></script>
<script defer src=/notes/en.search.min.8559063499cfd5c826524434e1a9e219fe0dea19bc655f26497621d4f7310f4f.js integrity="sha256-hVkGNJnP1cgmUkQ04aniGf4N6hm8ZV8mSXYh1PcxD08=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/notes/><span>Aditya's notes</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-a88f46c31d1ebdf165810583424fda37 class=toggle>
<label for=section-a88f46c31d1ebdf165810583424fda37 class="flex justify-between"><a role=button>CS 103, Fall 2020</a></label><ul><li><a href=/notes/cs103/2020-09-16-set-theory/>Set Theory</a></li><li><a href=/notes/cs103/2020-09-18-indirect-proofs/>Indirect Proofs</a></li><li><a href=/notes/cs103/2020-09-18-mathematical-proofs/>Mathematical Proofs</a></li><li><a href=/notes/cs103/2020-09-26-first-order-logic/>First Order Logic</a></li><li><a href=/notes/cs103/2020-09-26-propositional-logic/>Propositional Logic</a></li><li><a href=/notes/cs103/2020-09-27-first-order-logic-continued/>First Order Logic Continued</a></li><li><a href=/notes/cs103/2020-09-30-binary-relations/>Binary Relations</a></li><li><a href=/notes/cs103/2020-10-01-binary-relations-continued/>Binary Relations Continued</a></li><li><a href=/notes/cs103/2020-10-04-functions/>Functions</a></li><li><a href=/notes/cs103/2020-10-10-cardinality/>Cardinality</a></li><li><a href=/notes/cs103/2020-10-11-graph-theory/>Graph Theory</a></li><li><a href=/notes/cs103/2020-10-17-pigeonhole-principle/>Pigeonhole Principle</a></li><li><a href=/notes/cs103/2020-10-18-induction/>Induction</a></li><li><a href=/notes/cs103/2020-10-19-induction-variants/>Induction Variants</a></li><li><a href=/notes/cs103/2020-10-20-computability-and-formal-languages/>Computability and Formal Languages</a></li><li><a href=/notes/cs103/2020-10-25-nondeterministic-finite-automata/>Nondeterministic Finite Automata</a></li><li><a href=/notes/cs103/2020-10-26-nfa-dfa-equivalence/>Nfa Dfa Equivalence</a></li><li><a href=/notes/cs103/2020-10-26-regular-expressions/>Regular Expressions</a></li><li><a href=/notes/cs103/2020-11-01-nonregular-languages/>Nonregular Languages</a></li><li><a href=/notes/cs103/2020-11-02-context-free-grammars/>Context Free Grammars</a></li><li><a href=/notes/cs103/2020-11-03-turing-machines/>Turing Machines</a></li><li><a href=/notes/cs103/2020-11-08-turing-machine-subroutines/>Turing Machine Subroutines</a></li><li><a href=/notes/cs103/2020-11-08-universal-turing-machine/>Universal Turing Machine</a></li><li><a href=/notes/cs103/2020-11-08-unsolvable-problems/>Unsolvable Problems</a></li><li><a href=/notes/cs103/2020-11-14-unsolvable-problems-continued/>Unsolvable Problems Continued</a></li></ul></li><li><input type=checkbox id=section-cf13475a7a80a5dd57b5a55dce73d171 class=toggle>
<label for=section-cf13475a7a80a5dd57b5a55dce73d171 class="flex justify-between"><a role=button>CS 107, Fall 2020</a></label><ul><li><a href=/notes/cs107/2020-09-18-integer-representations/>Integer Representations</a></li><li><a href=/notes/cs107/2020-09-21-bitwise-operations/>Bitwise Operations</a></li><li><a href=/notes/cs107/2020-09-25-c-chars-and-strings/>C Chars and Strings</a></li><li><a href=/notes/cs107/2020-09-28-more-c-strings/>More C Strings</a></li><li><a href=/notes/cs107/2020-10-02-pointers-arrays/>Pointers Arrays</a></li><li><a href=/notes/cs107/2020-10-05-stack-and-heap/>Stack and Heap</a></li><li><a href=/notes/cs107/2020-10-09-c-generics/>C Generics</a></li><li><a href=/notes/cs107/2020-10-12-function-pointers/>Function Pointers</a></li><li><a href=/notes/cs107/2020-10-16-assembly/>Assembly</a></li><li><a href=/notes/cs107/2020-10-19-assembly-arithmetic-logic/>Assembly Arithmetic Logic</a></li><li><a href=/notes/cs107/2020-10-23-assembly-control-flow/>Assembly Control Flow</a></li><li><a href=/notes/cs107/2020-10-26-assembly-function-calls-and-return-stack/>Assembly Function Calls and Return Stack</a></li><li><a href=/notes/cs107/2020-10-30-heap-management/>Heap Management</a></li><li><a href=/notes/cs107/2020-11-09-program-optimization/>Program Optimization</a></li></ul></li><li><input type=checkbox id=section-4e3bc6e2f7a0feae33c3e43356d49c80 class=toggle>
<label for=section-4e3bc6e2f7a0feae33c3e43356d49c80 class="flex justify-between"><a role=button>CS 110L, Spring 2021</a></label><ul><li><a href=/notes/cs110l/2021-03-30-course-overview/>Course Overview</a></li><li><a href=/notes/cs110l/2021-04-01-fixing-c/>Fixing C</a></li><li><a href=/notes/cs110l/2021-04-06-intro-to-rust/>Intro to Rust</a></li><li><a href=/notes/cs110l/2021-04-08-ownership/>Ownership</a></li><li><a href=/notes/cs110l/2021-04-13-error-handling/>Error Handling</a></li><li><a href=/notes/cs110l/2021-04-22-traits/>Traits</a></li><li><a href=/notes/cs110l/2021-04-27-generics/>Generics</a></li><li><a href=/notes/cs110l/2021-04-29-multiprocessing/>Multiprocessing</a></li></ul></li><li><input type=checkbox id=section-23e7773af736437c02202412a988f2db class=toggle>
<label for=section-23e7773af736437c02202412a988f2db class="flex justify-between"><a role=button>CS 111, Spring 2021</a></label><ul><li><a href=/notes/cs111/2021-03-31-threads-and-dispatching/>Threads and Dispatching</a></li><li><a href=/notes/cs111/2021-04-02-concurrency/>Concurrency</a></li><li><a href=/notes/cs111/2021-04-05-synchronization/>Synchronization</a></li><li><a href=/notes/cs111/2021-04-07-shared-memory-and-condition-variables-and-locks/>Shared Memory and Condition Variables and Locks</a></li><li><a href=/notes/cs111/2021-04-09-lock-implementation-and-deadlocking/>Lock Implementation and Deadlocking</a></li><li><a href=/notes/cs111/2021-04-12-scheduling/>Scheduling</a></li><li><a href=/notes/cs111/2021-04-14-multiprocessing/>Multiprocessing</a></li><li><a href=/notes/cs111/2021-04-16-linking/>Linking</a></li><li><a href=/notes/cs111/2021-04-19-storage-management/>Storage Management</a></li><li><a href=/notes/cs111/2021-04-21-virtual-memory/>Virtual Memory</a></li><li><a href=/notes/cs111/2021-04-23-dynamic-address-translation/>Dynamic Address Translation</a></li><li><a href=/notes/cs111/2021-04-26-segmentation-and-paging/>Segmentation and Paging</a></li><li><a href=/notes/cs111/2021-04-30-demand-paging/>Demand Paging</a></li><li><a href=/notes/cs111/2021-05-05-disks/>Disks</a></li><li><a href=/notes/cs111/2021-05-07-file-systems/>File Systems</a></li><li><a href=/notes/cs111/2021-05-10-realworld-filesystem-structures/>Realworld Filesystem Structures</a></li><li><a href=/notes/cs111/2021-05-12-directories/>Directories</a></li><li><a href=/notes/cs111/2021-05-14-crash-recovery/>Crash Recovery</a></li><li><a href=/notes/cs111/2021-05-19-protection/>Protection</a></li><li><a href=/notes/cs111/2021-05-24-flash-memory/>Flash Memory</a></li><li><a href=/notes/cs111/2021-05-28-virtual-machines/>Virtual Machines</a></li></ul></li><li><input type=checkbox id=section-a586b190ebf0a4874cd21a1d76743261 class=toggle>
<label for=section-a586b190ebf0a4874cd21a1d76743261 class="flex justify-between"><a role=button>CS 143, Spring 2022</a></label><ul><li><a href=/notes/cs143/2022-03-29-intro/>Intro</a></li><li><a href=/notes/cs143/2022-03-31-language-design-and-cool/>Language Design and Cool</a></li><li><a href=/notes/cs143/2022-04-05-lexical-analysis/>Lexical Analysis</a></li><li><a href=/notes/cs143/2022-04-07-lexical-analysis-implementation/>Lexical Analysis Implementation</a></li><li><a href=/notes/cs143/2022-04-12-parsing/>Parsing</a></li><li><a href=/notes/cs143/2022-04-14-syntax-directed-translation/>Syntax Directed Translation</a></li><li><a href=/notes/cs143/2022-04-19-top-down-parsing/>Top Down Parsing</a></li><li><a href=/notes/cs143/2022-04-26-semantic-analysis/>Semantic Analysis</a></li></ul></li><li><input type=checkbox id=section-37836de7a703e433b2642097d511f482 class=toggle checked>
<label for=section-37836de7a703e433b2642097d511f482 class="flex justify-between"><a role=button>CS 149, Fall 2022</a></label><ul><li><a href=/notes/cs149/2022-09-27-intro/>Intro</a></li><li><a href=/notes/cs149/2022-09-29-modern-multicore-processors/>Modern Multicore Processors</a></li><li><a href=/notes/cs149/2022-10-04-parallel-abstractions/>Parallel Abstractions</a></li><li><a href=/notes/cs149/2022-10-06-parallel-models/>Parallel Models</a></li><li><a href=/notes/cs149/2022-10-11-work-distribution-and-scheduling/>Work Distribution and Scheduling</a></li><li><a href=/notes/cs149/2022-10-13-locality-communication-and-contention/>Locality Communication and Contention</a></li><li><a href=/notes/cs149/2022-10-18-gpu-architecture-and-cuda/>Gpu Architecture and Cuda</a></li><li><a href=/notes/cs149/2022-10-20-data-parallel-architecture/>Data Parallel Architecture</a></li><li><a href=/notes/cs149/2022-10-25-spark/ class=active>Spark</a></li><li><a href=/notes/cs149/2022-10-27-cache-coherence/>Cache Coherence</a></li><li><a href=/notes/cs149/2022-11-01-memory-consistency/>Memory Consistency</a></li><li><a href=/notes/cs149/2022-11-03-lock-implementation-and-lock-free-programming/>Lock Implementation and Lock Free Programming</a></li><li><a href=/notes/cs149/2022-11-10-transactional-memory/>Transactional Memory</a></li></ul></li><li><input type=checkbox id=section-4f9fa520660f975442d4640415905b3c class=toggle>
<label for=section-4f9fa520660f975442d4640415905b3c class="flex justify-between"><a role=button>CS 154, Fall 2021</a></label><ul><li><a href=/notes/cs154/2021-09-28-finite-automata/>Finite Automata</a></li><li><a href=/notes/cs154/2021-10-05-pumping-lemma-and-myhill-nerode/>Pumping Lemma and Myhill Nerode</a></li><li><a href=/notes/cs154/2021-10-12-streaming-algorithms-and-turing-machines/>Streaming Algorithms and Turing Machines</a></li></ul></li><li><input type=checkbox id=section-d24cd7d7d21fe73135d596a09b50887f class=toggle>
<label for=section-d24cd7d7d21fe73135d596a09b50887f class="flex justify-between"><a role=button>CS 155, Spring 2022</a></label><ul><li><a href=/notes/cs155/2022-03-28-intro/>Intro</a></li><li><a href=/notes/cs155/2022-03-30-control-hijacking/>Control Hijacking</a></li><li><a href=/notes/cs155/2022-04-04-control-hijacking-defenses/>Control Hijacking Defenses</a></li><li><a href=/notes/cs155/2022-04-06-security-principles/>Security Principles</a></li><li><a href=/notes/cs155/2022-04-11-isolation-and-sandboxing/>Isolation and Sandboxing</a></li><li><a href=/notes/cs155/2022-04-13-vuln-finding/>Vuln Finding</a></li><li><a href=/notes/cs155/2022-04-18-web-security/>Web Security</a></li><li><a href=/notes/cs155/2022-04-20-web-attacks/>Web Attacks</a></li><li><a href=/notes/cs155/2022-04-25-web-defenses/>Web Defenses</a></li><li><a href=/notes/cs155/2022-05-04-processor-security/>Processor Security</a></li><li><a href=/notes/cs155/2022-05-09-internet-protocol-security/>Internet Protocol Security</a></li></ul></li><li><input type=checkbox id=section-471622039e8d87cd8d642483c8d218b8 class=toggle>
<label for=section-471622039e8d87cd8d642483c8d218b8 class="flex justify-between"><a role=button>CS 161, Winter 2022</a></label><ul><li><a href=/notes/cs161/2022-01-03-intro/>Intro</a></li><li><a href=/notes/cs161/2022-01-05-worst-case-and-asymptotic-analysis/>Worst Case and Asymptotic Analysis</a></li><li><a href=/notes/cs161/2022-01-10-recurrence-relations/>Recurrence Relations</a></li><li><a href=/notes/cs161/2022-01-12-median-and-selection/>Median and Selection</a></li><li><a href=/notes/cs161/2022-01-19-randomized-algorithms-and-quicksort/>Randomized Algorithms and Quicksort</a></li><li><a href=/notes/cs161/2022-01-24-sorting-lower-bounds/>Sorting Lower Bounds</a></li><li><a href=/notes/cs161/2022-01-26-binary-search-trees/>Binary Search Trees</a></li><li><a href=/notes/cs161/2022-01-31-hashing/>Hashing</a></li><li><a href=/notes/cs161/2022-02-02-graphs-and-graph-search/>Graphs and Graph Search</a></li><li><a href=/notes/cs161/2022-02-07-strongly-connected-components/>Strongly Connected Components</a></li><li><a href=/notes/cs161/2022-02-09-weighted-graphs-and-dijkstra/>Weighted Graphs and Dijkstra</a></li><li><a href=/notes/cs161/2022-02-14-dynamic-programming/>Dynamic Programming</a></li><li><a href=/notes/cs161/2022-02-16-dynamic-programming-applications/>Dynamic Programming Applications</a></li><li><a href=/notes/cs161/2022-02-23-greedy-algorithms/>Greedy Algorithms</a></li><li><a href=/notes/cs161/2022-02-28-minimum-spanning-trees/>Minimum Spanning Trees</a></li></ul></li><li><input type=checkbox id=section-0794dc87987599843ba69a8ea82e9b6a class=toggle>
<label for=section-0794dc87987599843ba69a8ea82e9b6a class="flex justify-between"><a role=button>CS 224U, Spring 2021</a></label><ul><li><a href=/notes/cs224u/2021-03-29-course-overview/>Course Overview</a></li><li><a href=/notes/cs224u/2021-03-31-vector-space-models/>Vector Space Models</a></li><li><a href=/notes/cs224u/2021-04-12-sentiment-analysis/>Sentiment Analysis</a></li></ul></li><li><input type=checkbox id=section-efae8264f5fe410feb1b40be6f99baea class=toggle>
<label for=section-efae8264f5fe410feb1b40be6f99baea class="flex justify-between"><a role=button>CS 229, Fall 2021</a></label><ul><li><a href=/notes/cs229/2021-09-21-intro/>Intro</a></li><li><a href=/notes/cs229/2021-09-23-supervised-learning-setup/>Supervised Learning Setup</a></li><li><a href=/notes/cs229/2021-09-28-logistic-regression/>Logistic Regression</a></li><li><a href=/notes/cs229/2021-09-30-generalized-linear-models/>Generalized Linear Models</a></li><li><a href=/notes/cs229/2021-10-05-generative-learning-algorithms/>Generative Learning Algorithms</a></li><li><a href=/notes/cs229/2021-10-07-naive-bayes/>Naive Bayes</a></li><li><a href=/notes/cs229/2021-10-12-kernel-methods-and-svm/>Kernel Methods and Svm</a></li><li><a href=/notes/cs229/2021-10-14-deep-learning/>Deep Learning</a></li><li><a href=/notes/cs229/2021-10-19-deep-learning-optimization/>Deep Learning Optimization</a></li><li><a href=/notes/cs229/2021-10-21-model-selection/>Model Selection</a></li></ul></li><li><input type=checkbox id=section-292ea4e126876f1048e61c4dc744546c class=toggle>
<label for=section-292ea4e126876f1048e61c4dc744546c class="flex justify-between"><a role=button>CS 251, Fall 2022</a></label><ul><li><a href=/notes/cs251/2022-09-26-intro/>Intro</a></li><li><a href=/notes/cs251/2022-09-28-bitcoin-mechanics/>Bitcoin Mechanics</a></li><li><a href=/notes/cs251/2022-10-03-bitcoin-scripts-and-wallets/>Bitcoin Scripts and Wallets</a></li><li><a href=/notes/cs251/2022-10-05-consensus/>Consensus</a></li><li><a href=/notes/cs251/2022-10-10-internet-consensus/>Internet Consensus</a></li><li><a href=/notes/cs251/2022-10-17-ethereum/>Ethereum</a></li><li><a href=/notes/cs251/2022-10-19-solidity/>Solidity</a></li><li><a href=/notes/cs251/2022-11-02-legal-aspects-and-regulation/>Legal Aspects and Regulation</a></li><li><a href=/notes/cs251/2022-11-07-privacy-and-deanonymization-and-mixing/>Privacy and Deanonymization and Mixing</a></li></ul></li><li><input type=checkbox id=section-98d861db134658b3e020a9d74c50ad24 class=toggle>
<label for=section-98d861db134658b3e020a9d74c50ad24 class="flex justify-between"><a role=button>CS 255, Winter 2022</a></label><ul><li><a href=/notes/cs255/2022-01-03-intro/>Intro</a></li><li><a href=/notes/cs255/2022-01-05-stream-ciphers/>Stream Ciphers</a></li><li><a href=/notes/cs255/2022-01-10-block-ciphers/>Block Ciphers</a></li><li><a href=/notes/cs255/2022-01-12-pseudorandom-functions/>Pseudorandom Functions</a></li><li><a href=/notes/cs255/2022-01-19-data-integrity-and-macs/>Data Integrity and Macs</a></li><li><a href=/notes/cs255/2022-01-24-collision-resistance/>Collision Resistance</a></li><li><a href=/notes/cs255/2022-01-26-authenticated-encryption/>Authenticated Encryption</a></li><li><a href=/notes/cs255/2022-01-31-key-management/>Key Management</a></li><li><a href=/notes/cs255/2022-02-02-key-exchange-math/>Key Exchange Math</a></li><li><a href=/notes/cs255/2022-02-07-public-key-encryption/>Public Key Encryption</a></li><li><a href=/notes/cs255/2022-02-09-pke-schemes/>Pke Schemes</a></li><li><a href=/notes/cs255/2022-02-14-digital-signatures/>Digital Signatures</a></li><li><a href=/notes/cs255/2022-02-16-certificates/>Certificates</a></li><li><a href=/notes/cs255/2022-02-23-id-protocols/>Id Protocols</a></li><li><a href=/notes/cs255/2022-02-28-key-exchange-protocols/>Key Exchange Protocols</a></li><li><a href=/notes/cs255/2022-03-02-zero-knowledge-protocols/>Zero Knowledge Protocols</a></li><li><a href=/notes/cs255/2022-03-07-quantum-cryptography/>Quantum Cryptography</a></li></ul></li><li><input type=checkbox id=section-568ed1bc8289796d56a6d06a22d7eb40 class=toggle>
<label for=section-568ed1bc8289796d56a6d06a22d7eb40 class="flex justify-between"><a role=button>INTLPOL 268, Fall 2021</a></label><ul><li><a href=/notes/intlpol268/2021-09-20-intro/>Intro</a></li><li><a href=/notes/intlpol268/2021-09-22-legal-intro-and-electronic-communications-privacy-act/>Legal Intro and Electronic Communications Privacy Act</a></li><li><a href=/notes/intlpol268/2021-09-27-web-requests-and-attacks/>Web Requests and Attacks</a></li><li><a href=/notes/intlpol268/2021-09-29-ecpa-for-private-actors/>Ecpa for Private Actors</a></li><li><a href=/notes/intlpol268/2021-10-04-cyberattacks/>Cyberattacks</a></li><li><a href=/notes/intlpol268/2021-10-06-computer-fraud-and-abuse-act/>Computer Fraud and Abuse Act</a></li><li><a href=/notes/intlpol268/2021-10-11-network-security/>Network Security</a></li><li><a href=/notes/intlpol268/2021-10-13-cfaa-dmca-and-security-research/>Cfaa Dmca and Security Research</a></li><li><a href=/notes/intlpol268/2021-10-20-data-security-laws/>Data Security Laws</a></li><li><a href=/notes/intlpol268/2021-10-25-corporate-intrusion/>Corporate Intrusion</a></li><li><a href=/notes/intlpol268/2021-10-27-ransomware-and-foreign-hackers/>Ransomware and Foreign Hackers</a></li><li><a href=/notes/intlpol268/2021-11-01-cryptography/>Cryptography</a></li><li><a href=/notes/intlpol268/2021-11-03-cyber-conflict/>Cyber Conflict</a></li><li><a href=/notes/intlpol268/2021-11-08-dark-web-and-cryptocurrencies/>Dark Web and Cryptocurrencies</a></li><li><a href=/notes/intlpol268/2021-11-10-encryption-and-technical-assistance/>Encryption and Technical Assistance</a></li><li><a href=/notes/intlpol268/2021-11-15-malware/>Malware</a></li><li><a href=/notes/intlpol268/2021-11-17-government-hacking/>Government Hacking</a></li><li><a href=/notes/intlpol268/2021-11-29-new-frontiers/>New Frontiers</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/notes/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Spark</strong>
<label for=toc-control><img src=/notes/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#spark-distributed-computing-on-a-cluster>Spark: Distributed Computing on a Cluster</a><ul><li><a href=#cluster-environment>Cluster environment</a><ul><li><a href=#why-use-a-cluster>Why use a cluster?</a></li><li><a href=#warehouse-scale-computing-wsc>Warehouse-scale computing (WSC)</a></li><li><a href=#storage-systems>Storage systems</a><ul><li><a href=#architecture-of-a-distributed-file-system>Architecture of a distributed file system</a></li></ul></li></ul></li><li><a href=#mapreduce-programming-model>MapReduce programming model</a><ul><li><a href=#mapreduce-steps>MapReduce steps</a></li><li><a href=#job-scheduler-responsibilities>Job scheduler responsibilities</a></li><li><a href=#mapreduce-limitations>MapReduce limitations</a></li><li><a href=#canonical-example-word-count>Canonical example: Word count</a></li><li><a href=#example-massive-cs149>Example: Massive CS149</a></li></ul></li><li><a href=#apache-spark>Apache Spark</a><ul><li><a href=#fault-tolerance-for-in-memory-calculations>Fault-tolerance for in-memory calculations</a></li><li><a href=#resilient-distributed-dataset-rdd-sparks-key-abstraction>Resilient Distributed Dataset (RDD): Spark&rsquo;s key abstraction</a></li><li><a href=#rdd-constraints-and-optimization>RDD constraints and optimization</a></li><li><a href=#modern-spark-ecosystem>Modern Spark ecosystem</a></li></ul></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=spark-distributed-computing-on-a-cluster>Spark: Distributed Computing on a Cluster
<a class=anchor href=#spark-distributed-computing-on-a-cluster>#</a></h1><h2 id=cluster-environment>Cluster environment
<a class=anchor href=#cluster-environment>#</a></h2><ul><li>Main idea: distributed computing, programming with 10k-100k cares<ul><li>How to ensure no data loss in case of failure of some system component?</li><li>Programming model: data-parallel operations (e.g. Map and Reduce)</li></ul></li><li>Goal: make data-parallel operations<ul><li>Scalable (100ks of cores)</li><li>Fault-tolerant (ensure no data loss in case of failure)</li><li>Efficient (optimize system perf. with efficient use of memory)</li></ul></li></ul><h3 id=why-use-a-cluster>Why use a cluster?
<a class=anchor href=#why-use-a-cluster>#</a></h3><ul><li>e.g. want to process 100TB of log data (e.g. 1 day at Facebook)<ul><li>On a single node: scanning at 50 MB/s = 23 days</li><li>On 1000 nodes: scanning at 50 MB/s = 33 min</li></ul></li><li>However: hard to use that many nodes<ul><li>Hard to program that many cores</li><li>Potential failures at that scale</li><li>Need framework to handle this</li></ul></li></ul><h3 id=warehouse-scale-computing-wsc>Warehouse-scale computing (WSC)
<a class=anchor href=#warehouse-scale-computing-wsc>#</a></h3><ul><li>Standard architecture:<ul><li>Cluster of commodity Linux nodes (e.g. multicore x86)<ul><li>Usually 16-32 core CPUs, 128 GB-1 TB of DRAM, 10-30 TB of SSD storage</li><li>RAM bandwidth: 100 GB/s</li><li>SSD bandwidth: 1-4 GB/s</li></ul></li><li>Private memory: separate address space and separate OS</li><li>Ethernet network: >10GB today<ul><li>&ldquo;top-of-rack&rdquo; switch connects all the nodes in a rack (1-2 GB/s) with nodes in other racks (0.1-2 GB/s)</li></ul></li></ul></li><li>Cheap:<ul><li>Build from commodity hardware</li><li>Thousands of nodes for &lt;$10M</li></ul></li><li>Goal: use supercomputer networking ideas to provide high bandwidth across datacenter<ul><li>However: need to mask issues such as load balancing and failures</li></ul></li></ul><h3 id=storage-systems>Storage systems
<a class=anchor href=#storage-systems>#</a></h3><ul><li>First order problem: if nodes can fail, how to store data persistently?</li><li>Distributed file systems:<ul><li>Google GFS</li><li>Hadoop HDFS (open-source)</li></ul></li><li>Typical usage pattern:<ul><li>Huge files (100s of GBs to TBs)</li><li>Data rarely updated in place</li><li>Reads and appends common (e.g. log files)</li></ul></li></ul><h4 id=architecture-of-a-distributed-file-system>Architecture of a distributed file system
<a class=anchor href=#architecture-of-a-distributed-file-system>#</a></h4><ul><li>Chunk servers or HDFS DataNode<ul><li>File split into contiguous chunks (usually 64-256 MB)</li><li>Each chunk replicated 2-3x</li><li>Try to keep replicas in different racks</li></ul></li><li>Master node or HDFS NameNode<ul><li>Stores metadata, usually replicated</li></ul></li><li>Client library for file access<ul><li>Talks to master node to find chunk servers</li><li>Connects directly to chunk servers to access data</li></ul></li></ul><h2 id=mapreduce-programming-model>MapReduce programming model
<a class=anchor href=#mapreduce-programming-model>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span><span style=color:#6272a4>// called once per block of input by runtime
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span><span style=color:#8be9fd>void</span> <span style=color:#50fa7b>mapper</span>(string inp, multimap<span style=color:#ff79c6>&lt;</span>string, string<span style=color:#ff79c6>&gt;&amp;</span> results);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4>// called once per unique key in results
</span></span></span><span style=display:flex><span><span style=color:#6272a4>// values is a list of values associiated with the given key
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span><span style=color:#8be9fd>void</span> <span style=color:#50fa7b>reducer</span>(string key, list<span style=color:#ff79c6>&lt;</span>string<span style=color:#ff79c6>&gt;</span> values, <span style=color:#8be9fd>int</span><span style=color:#ff79c6>&amp;</span> result);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Writer <span style=color:#50fa7b>output</span>(<span style=color:#f1fa8c>&#34;hdfs://&#34;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>runMapReduceJob(mapper, reducer, input, output);
</span></span></code></pre></div><h3 id=mapreduce-steps>MapReduce steps
<a class=anchor href=#mapreduce-steps>#</a></h3><ol><li>Run mapper function on all lines of file<ul><li>Question: how to assign work to nodes?</li><li>Solution: Data-distribution based assignment: each node processes lines in blocks of input file that are stored locally</li></ul></li><li>Prepare intermediate data for reducer</li><li>Run reducer function on all keys<ul><li>Question: how to get all data for key onto the correct reduce worker node?</li><li>Solution: directive from master, assign each type of key to a node</li></ul></li></ol><h3 id=job-scheduler-responsibilities>Job scheduler responsibilities
<a class=anchor href=#job-scheduler-responsibilities>#</a></h3><ul><li>Exploit data locality: &ldquo;move computation to the data&rdquo;<ul><li>Run mapper jobs on nodes that contain input files</li><li>Run reducer jobs on nodes that already have most data for a certain key</li></ul></li><li>Handling node failures<ul><li>Scheduler detects job failures and reruns them on new machines</li><li>Possible since inputs reside in persistent storage (distributed file system)</li><li>Scheduler duplicates jobs on multiple machines (reduce overall processing latency incurred by node failures)</li></ul></li><li>Handling slow machines<ul><li>Scheduler duplicates jobs on multiple machines</li></ul></li></ul><h3 id=mapreduce-limitations>MapReduce limitations
<a class=anchor href=#mapreduce-limitations>#</a></h3><ul><li>Permits only simple program structure: must be map, followed by reduce by key<ul><li>Generalization to DAGs: DryadLINQ, however support is not easy</li></ul></li><li>Iterative algorithms must load from disk each iteration</li><li>This limits more complex, multi-stage applications (e.g. iterative ML and graph processing)</li></ul><h3 id=canonical-example-word-count>Canonical example: Word count
<a class=anchor href=#canonical-example-word-count>#</a></h3><ul><li>Input: documents containing some amount of words<ul><li>e.g.<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>inp <span style=color:#ff79c6>=</span> [
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;the quick brown fox&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;the fox ate the mouse&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;how now brown cow&#34;</span>
</span></span><span style=display:flex><span>]
</span></span></code></pre></div></li></ul></li><li>Desired outputs: how many times is each word used?<ul><li>e.g.<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;brown&#34;</span>: <span style=color:#bd93f9>2</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;fox&#34;</span>: <span style=color:#bd93f9>2</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;how&#34;</span>: <span style=color:#bd93f9>1</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;now&#34;</span>: <span style=color:#bd93f9>1</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;the&#34;</span>: <span style=color:#bd93f9>3</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;ate&#34;</span>: <span style=color:#bd93f9>1</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;cow&#34;</span>: <span style=color:#bd93f9>1</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;mouse&#34;</span>: <span style=color:#bd93f9>1</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;quick&#34;</span>: <span style=color:#bd93f9>1</span>
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></li></ul></li><li>Example computation: map a function that does partial word count onto each document, then reduce jobs to aggregate</li></ul><h3 id=example-massive-cs149>Example: Massive CS149
<a class=anchor href=#example-massive-cs149>#</a></h3><ul><li>Assume <code>cs149log.txt</code> is a large file containing a log of web requests to CS149 site<ul><li>Stored in a distributed FS like HDFS</li><li>Blocks of the log are stored across a cluster of 4 nodes</li></ul></li><li>Now: attempt to query about demographics of students visiting CS149 site (e.g. type of mobile phone)<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span><span style=color:#8be9fd>void</span> <span style=color:#50fa7b>mapper</span>(string line, multimap<span style=color:#ff79c6>&lt;</span>string, string<span style=color:#ff79c6>&gt;&amp;</span> results) {
</span></span><span style=display:flex><span>    string user_agent <span style=color:#ff79c6>=</span> parse_requester_user_agent(line);
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>if</span> (is_mobile_client(user_agent))
</span></span><span style=display:flex><span>        results.add(user_agent, <span style=color:#bd93f9>1</span>);
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8be9fd>void</span> <span style=color:#50fa7b>reducer</span>(string key, list<span style=color:#ff79c6>&lt;</span>string<span style=color:#ff79c6>&gt;</span> values, <span style=color:#8be9fd>int</span><span style=color:#ff79c6>&amp;</span> result) {
</span></span><span style=display:flex><span>    <span style=color:#8be9fd>int</span> sum <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>;
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> (string <span style=color:#8be9fd;font-style:italic>v</span> : values)
</span></span><span style=display:flex><span>        sum <span style=color:#ff79c6>+=</span> v;
</span></span><span style=display:flex><span>    result <span style=color:#ff79c6>=</span> sum;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Reader <span style=color:#50fa7b>input</span>(<span style=color:#f1fa8c>&#34;hdfs://cs149log.txt&#34;</span>);
</span></span><span style=display:flex><span>Writer <span style=color:#50fa7b>output</span>(<span style=color:#f1fa8c>&#34;hdfs://&#34;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>runMapReduceJob(mapper, reducer, input, output);
</span></span></code></pre></div></li></ul><h2 id=apache-spark>Apache Spark
<a class=anchor href=#apache-spark>#</a></h2><ul><li>Motivating idea: despite huge amounts of data, many working sets in big data clusters fit in memory (Ananthanarayanan et al. 2011)<ul><li>Spark: Zaharia et al. 2012</li></ul></li><li>Goals:<ul><li>Programming model for cluster-scale computations with significant intermediate dataset reuse</li><li>Don&rsquo;t want to incur inefficiency of writing intermediates to persistent distributed FS<ul><li>Keep data in memory!</li><li>Challenge: efficiently implementing fault-tolerance for in-memory calculations at scale</li></ul></li></ul></li></ul><h3 id=fault-tolerance-for-in-memory-calculations>Fault-tolerance for in-memory calculations
<a class=anchor href=#fault-tolerance-for-in-memory-calculations>#</a></h3><ul><li>Naive: replicate all computations, decreases peak throughput</li><li>Another idea: checkpoint and rollback<ul><li>Save state of program to persistent storage</li><li>Restart from last checkpoint on node failure</li></ul></li><li>Another idea: maintain log of updates (commands and data)<ul><li>Naive: high maintenance overhead</li><li>However, use MapReduce to cut overhead down!<ul><li>Checkpoints after each map/reduce step by writing results to FS</li><li>Scheduler&rsquo;s list of outstanding (but not-yet-complete) jobs is a log</li><li>Functional structure of programs allows for restart at granularity of single map/reduce invocation (rather than restarting entire program)</li></ul></li></ul></li></ul><h3 id=resilient-distributed-dataset-rdd-sparks-key-abstraction>Resilient Distributed Dataset (RDD): Spark&rsquo;s key abstraction
<a class=anchor href=#resilient-distributed-dataset-rdd-sparks-key-abstraction>#</a></h3><ul><li>Read-only, ordered, immutable collection of records</li><li>RDDs can only be created by deterministic transformations on data in persistant storage or on existing RDDs</li><li>Actions on RDDs return data to application</li><li>e.g. CS149 mobile counting<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#6272a4>// create RDD from FS data
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span><span style=color:#ff79c6>val</span> lines <span style=color:#ff79c6>=</span> spark<span style=color:#ff79c6>.</span>textFile<span style=color:#ff79c6>(</span><span style=color:#f1fa8c>&#34;hdfs://cs149log.txt&#34;</span><span style=color:#ff79c6>);</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4>// create RDD using filter() transformation on lines
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span><span style=color:#ff79c6>val</span> mobileViews <span style=color:#ff79c6>=</span> lines<span style=color:#ff79c6>.</span>filter<span style=color:#ff79c6>((</span>x <span style=color:#ff79c6>:</span> <span style=color:#8be9fd>String</span><span style=color:#ff79c6>)</span> <span style=color:#ff79c6>=&gt;</span> isMobileClient<span style=color:#ff79c6>(</span>x<span style=color:#ff79c6>));</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4>// another filter() transformation
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span><span style=color:#ff79c6>val</span> safariViews <span style=color:#ff79c6>=</span> mobileViews<span style=color:#ff79c6>.</span>filter<span style=color:#ff79c6>((</span>x<span style=color:#ff79c6>:</span> <span style=color:#8be9fd>String</span><span style=color:#ff79c6>)</span> <span style=color:#ff79c6>=&gt;</span> x<span style=color:#ff79c6>.</span>contains<span style=color:#ff79c6>(</span><span style=color:#f1fa8c>&#34;Safari&#34;</span><span style=color:#ff79c6>));</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4>// then count number of elements in RDD via count() action
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span><span style=color:#ff79c6>val</span> numViews <span style=color:#ff79c6>=</span> safariViews<span style=color:#ff79c6>.</span>count<span style=color:#ff79c6>();</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4>// one-liner for aggregating view counts across different user agents
</span></span></span><span style=display:flex><span><span style=color:#6272a4>// at each step, &#34;lineage&#34;: sequence of RDD ops needed to compute output
</span></span></span><span style=display:flex><span><span style=color:#6272a4>// allows checkpointing for failure resistance
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span><span style=color:#ff79c6>val</span> perAgentCounts <span style=color:#ff79c6>=</span> spark
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>.</span>textFile<span style=color:#ff79c6>(</span><span style=color:#f1fa8c>&#34;hdfs://cs149log.txt&#34;</span><span style=color:#ff79c6>)</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>.</span>filter<span style=color:#ff79c6>(</span>x <span style=color:#ff79c6>=&gt;</span> isMobileClient<span style=color:#ff79c6>(</span>x<span style=color:#ff79c6>))</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>.</span>map<span style=color:#ff79c6>(</span>x <span style=color:#ff79c6>=&gt;</span> <span style=color:#ff79c6>(</span>parseUserAgent<span style=color:#ff79c6>(</span>x<span style=color:#ff79c6>),</span> <span style=color:#bd93f9>1</span><span style=color:#ff79c6>))</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>.</span>reduceByKey<span style=color:#ff79c6>((</span>x<span style=color:#ff79c6>,</span> y<span style=color:#ff79c6>)</span> <span style=color:#ff79c6>=&gt;</span> x<span style=color:#ff79c6>+</span>y<span style=color:#ff79c6>)</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>.</span>collect<span style=color:#ff79c6>();</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4>// can also do forks and forked computations for multiple results from a single RDD
</span></span></span></code></pre></div></li></ul><h3 id=rdd-constraints-and-optimization>RDD constraints and optimization
<a class=anchor href=#rdd-constraints-and-optimization>#</a></h3><ul><li>Storage<ul><li>Cannot keep entirely in memory: representation would be huge, larger than original file in disk</li></ul></li><li>Partitioning and dependencies<ul><li>Narrow dependencies: each partition of parent RDD referenced by at most one child RDD partition<ul><li>Allows for op fusing (e.g. can apply map, filter all at once on input element, saving on memory and disk usage)</li><li>Not necessary in all cases to communicate between nodes of cluster for transformation, only for reduce step at end</li></ul></li><li>Wide dependencies: each partition of parent RDD needs to be referenced by multiple child RDD partitions<ul><li>Requires dependency sorting that may induce communication</li><li>May trigger significant recomputation of ancestor lineage in failure case</li></ul></li><li>Choice of partitioning impacts whether narrow dependencies are possible or if wide dependencies are needed, e.g.<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#6272a4>// map keys to integers
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span><span style=color:#ff79c6>val</span> partitioner <span style=color:#ff79c6>=</span> spark<span style=color:#ff79c6>.</span><span style=color:#50fa7b>HashPartitioner</span><span style=color:#ff79c6>(</span><span style=color:#bd93f9>100</span><span style=color:#ff79c6>);</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4>// inform Spark of partition
</span></span></span><span style=display:flex><span><span style=color:#6272a4>// .persist(): instructs Spark to try to keep dataset in memory
</span></span></span><span style=display:flex><span><span style=color:#6272a4>// note: .persist(RELIABLE): store contents in durable storage (i.e., checkpoint it)
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span><span style=color:#ff79c6>val</span> mobileViewPartitioned <span style=color:#ff79c6>=</span> mobileViews<span style=color:#ff79c6>.</span>partitionBy<span style=color:#ff79c6>(</span>partitioner<span style=color:#ff79c6>).</span>persist<span style=color:#ff79c6>();</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>val</span> clientInfoPartitioned <span style=color:#ff79c6>=</span> clientInfo<span style=color:#ff79c6>.</span>partitionBy<span style=color:#ff79c6>(</span>partitioner<span style=color:#ff79c6>).</span>persist<span style=color:#ff79c6>();</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4>// due to explicit partitioning, only creates narrow dependencies
</span></span></span><span style=display:flex><span><span style=color:#6272a4></span>void joined <span style=color:#ff79c6>=</span> mobileViewPartitioned<span style=color:#ff79c6>.</span>join<span style=color:#ff79c6>(</span>clientInfoPartitioned<span style=color:#ff79c6>);</span>
</span></span></code></pre></div></li></ul></li><li>Node failure case: recomputing lost RDD partitions from lineage<ul><li>Must reload subset of data from disk and recompute entire sequence of operations given by lineage to regenerate missing partitions</li></ul></li></ul><h3 id=modern-spark-ecosystem>Modern Spark ecosystem
<a class=anchor href=#modern-spark-ecosystem>#</a></h3><ul><li>Compelling feature: enables integration/composition of multiple domain-specific frameworks, all implemented with RDDs<ul><li>e.g. Spark SQL: Interleave computation and data query</li><li>e.g. MLib: ML library on top of spark abstractions</li></ul></li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#spark-distributed-computing-on-a-cluster>Spark: Distributed Computing on a Cluster</a><ul><li><a href=#cluster-environment>Cluster environment</a><ul><li><a href=#why-use-a-cluster>Why use a cluster?</a></li><li><a href=#warehouse-scale-computing-wsc>Warehouse-scale computing (WSC)</a></li><li><a href=#storage-systems>Storage systems</a><ul><li><a href=#architecture-of-a-distributed-file-system>Architecture of a distributed file system</a></li></ul></li></ul></li><li><a href=#mapreduce-programming-model>MapReduce programming model</a><ul><li><a href=#mapreduce-steps>MapReduce steps</a></li><li><a href=#job-scheduler-responsibilities>Job scheduler responsibilities</a></li><li><a href=#mapreduce-limitations>MapReduce limitations</a></li><li><a href=#canonical-example-word-count>Canonical example: Word count</a></li><li><a href=#example-massive-cs149>Example: Massive CS149</a></li></ul></li><li><a href=#apache-spark>Apache Spark</a><ul><li><a href=#fault-tolerance-for-in-memory-calculations>Fault-tolerance for in-memory calculations</a></li><li><a href=#resilient-distributed-dataset-rdd-sparks-key-abstraction>Resilient Distributed Dataset (RDD): Spark&rsquo;s key abstraction</a></li><li><a href=#rdd-constraints-and-optimization>RDD constraints and optimization</a></li><li><a href=#modern-spark-ecosystem>Modern Spark ecosystem</a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>